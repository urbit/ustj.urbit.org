<!DOCTYPE html> 
<html lang="en" xml:lang="en" > 
<head><title>The Desert of the Reals: Floating-Point Arithmetic on
Deterministic Systems</title> 
<meta  charset="utf-8" /> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="/latex.css" /> 
<meta name="src" content="mss.tex" /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script type="text/javascript" async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>  
</head><body 
>
   <div class="maketitle">
                                                
                                                
                                                
                                                

<h2 class="titleHead">The Desert of the Reals:
Floating-Point Arithmetic on
Deterministic Systems</h2>
<div class="author" ><span 
class="ec-lmbx-12">N. E. Davis</span><span 
class="ec-lmbx-12"> </span><span 
class="ec-lmbx-12"><code>~lagrev-nocfep</code></span>
<br />      <span 
class="ec-lmbx-12">Urbit Foundation</span></div><br />
<div class="date" ></div>
   </div>
   <section role="doc-abstract" class="abstract"> 
<h3 class="abstracttitle">
<span 
class="ec-lmbx-9">Abstract</span>
</h3>
     <!--l. 35--><p class="noindent" ><span 
class="ec-lmr-9">Floating-point calculations are critical to a number</span>
     <span 
class="ec-lmr-9">of                      special                      domains</span>
     <span 
class="ec-lmr-9">in modern computing, including machine learning,</span>
     <span 
class="ec-lmr-9">graphics,  and  scientiﬁc  computing.  Numerical</span>
     <span 
class="ec-lmr-9">calculations are particularly susceptible to opaque</span>
     <span 
class="ec-lmr-9">and system-local optimizations, which can break</span>
     <span 
class="ec-lmr-9">certain guarantees for deterministic computers. We</span>
     <span 
class="ec-lmr-9">consider  the  background  and  implementation  of</span>
     <span 
class="ec-lmcsc-10x-x-90 small-caps">ieee </span><span 
class="ec-lmr-9">754 ﬂoating-point arithmetic and options for</span>
     <span 
class="ec-lmr-9">implementing mathematics compatibly with fully</span>
     <span 
class="ec-lmr-9">reproducible and portable computing. We consider</span>
     <span 
class="ec-lmr-9">hardware-based and software-based proposals.</span>
                                                
                                                
</p>
</section>
   <h3 class="likesectionHead"><a  id="x1-1000"></a>Contents</h3>
   <div class="tableofcontents">
    <span class="sectionToc" >1 <a href="#x1-20001" id="QQ2-1-2">Introduction</a></span>
<br />    <span class="sectionToc" >2 <a href="#x1-30002" id="QQ2-1-3">A Derivation of the Real Numbers</a></span>
<br />     <span class="subsectionToc" >2.1 <a href="#x1-40002.1" id="QQ2-1-4"><span class="small-caps">ieee</span> 754 Basics</a></span>
<br />    <span class="sectionToc" >3 <a href="#x1-130003" id="QQ2-1-14">Urbit’s Implementation of <span class="small-caps"><strong>ieee</strong></span> 754</a></span>
<br />    <span class="sectionToc" >4 <a href="#x1-140004" id="QQ2-1-15">Deterministic Computation with Fractional Part</a></span>
<br />     <span class="subsectionToc" >4.1 <a href="#x1-150004.1" id="QQ2-1-16">Hardware-supported ﬂoating-point arithmetic</a></span>
<br />      <span class="subsubsectionToc" >4.1.1 <a href="#x1-160004.1.1" id="QQ2-1-17">Control the stack</a></span>
<br />      <span class="subsubsectionToc" >4.1.2 <a href="#x1-170004.1.2" id="QQ2-1-18">Simulate the hardware</a></span>
<br />      <span class="subsubsectionToc" >4.1.3 <a href="#x1-180004.1.3" id="QQ2-1-19">Support a single hardware platform</a></span>
<br />      <span class="subsubsectionToc" >4.1.4 <a href="#x1-190004.1.4" id="QQ2-1-20">Dock ﬂoating-point results</a></span>
<br />      <span class="subsubsectionToc" >4.1.5 <a href="#x1-200004.1.5" id="QQ2-1-21">Consistency checks</a></span>
<br />     <span class="subsectionToc" >4.2 <a href="#x1-210004.2" id="QQ2-1-22">Software-deﬁned ﬂoating-point library</a></span>
<br />     <span class="subsectionToc" >4.3 <a href="#x1-220004.3" id="QQ2-1-23">Opaque calculations</a></span>
<br />     <span class="subsectionToc" >4.4 <a href="#x1-230004.4" id="QQ2-1-24">Stored results</a></span>
<br />     <span class="subsectionToc" >4.5 <a href="#x1-240004.5" id="QQ2-1-25">Proscribing <span 
class="ec-lmcsc-10">ieee </span>754</a></span>
<br />     <span class="subsectionToc" >4.6 <a href="#x1-300004.6" id="QQ2-1-31">Irregularities</a></span>
<br />    <span class="sectionToc" >5 <a href="#x1-310005" id="QQ2-1-32">Linear Algebra in Hoon</a></span>
<br />    <span class="sectionToc" >6 <a href="#x1-320006" id="QQ2-1-33">Conclusion</a></span>
<br />    <span class="sectionToc" ><a href="#x1-33000" id="QQ2-1-34">References</a></span>
   </div>
<!--l. 44--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a  id="x1-20001"></a>Introduction</h3>
<!--l. 46--><p class="noindent" >
     </p><blockquote class="quote">
                                                
                                                
     <!--l. 47--><p class="noindent" >Floating-point  operations  are  a  technically
     complex  subject  and  the  extent  to  which
     developers  or  source  code  alter  or  test  this
     information  will  depend  on  many  factors.
     Apart   from   the   general   exhortation   to
     developers to be careful and to make sure they
     know  what  they  are  doing,  there  is  little  of
     practical use that can be recommended. (<a  id="x1-2001"></a> Jones
     (2008), p. 197)</p></blockquote>
<!--l. 50--><p class="noindent" >Modern digital computers deal, at their root,
in binary representation, entirely zeros and
ones.<span class="footnote-mark"><a href="#fn1x0"><sup class="textsuperscript">1</sup></a></span><a  id="x1-2002f1"></a> 
These are often formally considered to be whole numbers in a
number base of two. However, numerical calculations very
frequently require the use of numbers with a fractional part to
adequately represent the elements of a computation.
</p><!--l. 53--><p class="indent" >   Early numeric computing tended to focus on problems of
interest to military and national security applications, such as
the solution of diﬀerential equations and numerical optimization.
Such calculations typically involve arrays, and linear algebra was
elaborated hand-in-hand with digital computing techniques in
software and hardware. Numerics assumed prominence for
a wider audience with the rise of gaming on personal
computers, although these algorithms emphasized speed over
exactness.<span class="footnote-mark"><a href="#fn2x0"><sup class="textsuperscript">2</sup></a></span><a  id="x1-2003f2"></a> 
To this point in the history of computing, most software either
ran on a single platform for its lifetime (as with supercomputing)
or did not require portably deterministic algorithms (as with
                                                
                                                
gaming).<span class="footnote-mark"><a href="#fn3x0"><sup class="textsuperscript">3</sup></a></span><a  id="x1-2004f3"></a> 
</p><!--l. 55--><p class="indent" >   On the other hand, deterministic computing describes the
ability for a given computation be reproducible exactly.
Such reproducibility permits referential transparency and
more powerful reasoning about a program’s results and
dependencies. This includes, for Urbit as a state machine, that
the event log replay be portable across platforms to yield the
same result. Conceptual guarantees must be backstopped by
actual implementation guarantees for determinism to
hold.
</p>
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a  id="x1-30002"></a>A Derivation of the Real Numbers</h3>
<!--l. 60--><p class="noindent" >Binary computer values are at root easily represented as
non-negative integers. However, it is frequently convenient
when working with human applications to either use other
numeric bases (notably decimal and hexadecimal) or to permit
non-integer mathematics.
</p><!--l. 62--><p class="indent" >   In the historical development of mathematics, logical
problems in each set of numbers drove the discovery and
elaboration of more elaborate algebras. For instance, in the
ﬁeld of natural numbers \(\mathbb {N}\), the operation of addition \(+\) or
multiplication \(\times \) produces a value within the set; however,
permitting subtraction \(-\) of a larger number from a
smaller number can result in a value inexpressible in
\(\mathbb {N}\). This motivated the introduction of the integers \(\mathbb {Z}\),
augmenting the numbers from zero to (positive) inﬁnity with
the negative numbers. Division \(/\) similarly produced a
crisis when applied to values which did not have a
whole-number ratio between them, a situation resolved by the
                                                
                                                
Pythagorean<span class="footnote-mark"><a href="#fn4x0"><sup class="textsuperscript">4</sup></a></span><a  id="x1-3001f4"></a> 
innovation of the rational numbers or fractions as a class \(\mathbb {Q}\).
Ultimately, the common reference set for engineering
mathematics (and the human understanding of the continuum
such as measurement) is the set of real numbers. The
set of real numbers, denoted by \(\mathbb {R}\), is characterized by
its continuity, implying that for any two distinct values
within this set, there exists a diﬀerence, no matter how
small.
</p><!--l. 65--><p class="indent" >   Since the operations and conventions of \(\mathbb {R}\) have been found
to be so useful, it is desirable to extend the semantics to
computer programming. However, digital computers, by virtue
of their binary representation, eﬀectively use natural numbers \(\mathbb {N}\)
to represent numbers (to the limit of memory rather than
positive inﬁnity \(+\infty \)). Several schemes permit a computer
integer to be interpreted as if it were a number with a
fractional part, including a scaling factor, ﬁxed-point
representation,<span class="footnote-mark"><a href="#fn5x0"><sup class="textsuperscript">5</sup></a></span><a  id="x1-3003f5"></a> 
and pairs as rational numbers.
</p><!--l. 67--><p class="indent" >   The basic concept of ﬂoating point arithmetic is that it
permits the representation of a discrete subset of \(\mathbb {R}\) by
composing a signiﬁcand, a base, and an exponent. The
signiﬁcand is the set of signiﬁcant digits, possibly including
the sign; the base is the understood number base (typically
2); and the exponent is the power to which that base is
put before multiplying by the signiﬁcand to yield the
                                                
                                                
result.<span class="footnote-mark"><a href="#fn6x0"><sup class="textsuperscript">6</sup></a></span><a  id="x1-3005f6"></a> 
The most ubiquitous ﬂoating-point format today is deﬁned by
the <span 
class="ec-lmcsc-10">ieee </span>754 standard, but certain hardware platforms
such as <span 
class="ec-lmcsc-10">gpu</span>s utilize alternative ﬂoating-point arithmetic
representations.<span class="footnote-mark"><a href="#fn7x0"><sup class="textsuperscript">7</sup></a></span><a  id="x1-3006f7"></a> 
</p><!--l. 69--><p class="indent" >   To summarize, given an abstract description of a ﬂoating
point system, there are several practical implementations that
can be derived. We need to specify at least four quantities:
sign,<span class="footnote-mark"><a href="#fn8x0"><sup class="textsuperscript">8</sup></a></span><a  id="x1-3009f8"></a>  signiﬁcand,
base, and exponent.<span class="footnote-mark"><a href="#fn9x0"><sup class="textsuperscript">9</sup></a></span><a  id="x1-3010f9"></a> 
The base is presumably ﬁxed by the protocol, leaving
three free values for the implementation to economically
encode.
</p>
   <h4 class="subsectionHead"><span class="titlemark">2.1   </span> <a  id="x1-40002.1"></a>IEEE 754 Basics</h4>
<!--l. 74--><p class="noindent" >Early computer systems with ﬂoating-point units chose
bespoke but incompatible representations, ultimately
leading to the <span 
class="ec-lmcsc-10">ieee </span>754 (primarily architected by
William Kahan). <span 
class="ec-lmcsc-10">ieee </span>754 reconciled considerations from
many ﬂoating-point implementations across hardware
manufacturers into an internally consistent set of ﬁxed-width
                                                
                                                
representations.<span class="footnote-mark"><a href="#fn10x0"><sup class="textsuperscript">10</sup></a></span><a  id="x1-4001f10"></a> 
For instance, the 32-bit “single precision” C ﬂoat/Fortran
REAL*4 speciﬁcation denotes particular bit positions as
meaningful,
</p>
   <!--l. 76-->
   <pre class="lstlisting" id="listing-1"><span class="label"><a  id="x1-4002r1"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">SEEE.EEEE.EFFF.FFFF.FFFF.FFFF.FFFF.FFFF</span></span></pre>
   
<!--l. 79--><p class="noindent" >where S is the sign bit, 0 for positive (\(+\)) and 1 for negative (\(-\));
E is the exponent in base-2 (8 bits); and F is the signiﬁcand
(23 bits). The exponent is actually calculated at an oﬀset bias
of 127 (\(2^{7}\)) so that a more expressive range of orders of
magnitude can be covered. The signiﬁcand has an implied
leading 1 bit unless all are zero. To wit,
</p><!--l. 82--><p class="indent" >
</p>
   <div class="math-display" >
<img 
src="mss0x.png" alt="(− 1)S × 2E−127 × 1.F
" class="math-display"  /></div>
<!--l. 85--><p class="noindent" ><span 
class="ec-lmcsc-10">ieee </span>754 speciﬁes operations between numbers, including of
diﬀerent magnitudes. The standard dictates behavior and
provides outlines for arithmetic, but leaves algorithmic details to
the implementation. Numbers are normalized by adjusting the
exponent of the smaller operand and aligning the signiﬁcands,
then the operations are carried out. In practice, extended
precision values are used in the intermediate steps of many
algorithms, leading to greater accuracy than would otherwise be
                                                
                                                
expected.<span class="footnote-mark"><a href="#fn11x0"><sup class="textsuperscript">11</sup></a></span><a  id="x1-4003f11"></a> 
</p><!--l. 89--><p class="indent" >   Since the <span 
class="ec-lmcsc-10">ieee </span>754 ﬂoating-point format packs values
of diﬀerent kind together bitwise, conventional integer
operations such as left shift \(&lt;&lt;\) and addition \(+\) do not trivially
apply.<span class="footnote-mark"><a href="#fn12x0"><sup class="textsuperscript">12</sup></a></span><a  id="x1-4007f12"></a> 
</p><!--l. 91--><p class="indent" >   Floating-point addition (add) proceeds per the following
algorithm:
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-4009x1">
     <!--l. 94--><p class="noindent" >Compare  exponents  of  the  two  numbers.  Shift
     the  smaller  number  rightwards  until  its  exponent
     matches the larger exponent.
     </p></li>
<li 
  class="enumerate" id="x1-4011x2">
     <!--l. 95--><p class="noindent" >Add the signiﬁcands together.
     </p></li>
<li 
  class="enumerate" id="x1-4013x3">
     <!--l. 96--><p class="noindent" >Normalize  the  sum  by  either  shifting  right  and
     incrementing  the  exponent,  or  shifting  left  and
                                                
                                                
     decrementing the exponent.
     </p></li>
<li 
  class="enumerate" id="x1-4015x4">
     <!--l. 97--><p class="noindent" >If  an  overﬂow  or  an  underﬂow  occurs,  yield  an
     exception.
     </p></li>
<li 
  class="enumerate" id="x1-4017x5">
     <!--l. 98--><p class="noindent" >Round the signiﬁcand to the appropriate number of
     bits.
     </p></li>
<li 
  class="enumerate" id="x1-4019x6">
     <!--l. 99--><p class="noindent" >Renormalize as necessary (back to step 3).</p></li></ol>
<!--l. 102--><p class="indent" >   <span 
class="ec-lmcsc-10">ieee </span>754 ﬂoating-point arithmetic and its predecessors
have some signiﬁcant mathematical compromises even in its
formal speciﬁcation. For instance, as a result of the discrete
nature of the bitwise representation in E and F, ﬂoating-point
mathematics are actually a subset of discrete mathematics
masquerading as real mathematics. This has non-trivial
consequences for certain aspects of calculations, including
error accrual. In particular, three facts dominate the
resolution:
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-4021x1">
     <!--l. 105--><p class="noindent" >The distance between two adjacent values changes
     based  on  the  magnitude  of  the  exponent  and  the
     distance from zero. (The signiﬁcand resolution stays
     the same but the exponent changes.)
     </p></li>
                                                
                                                
<li 
  class="enumerate" id="x1-4023x2">
     <!--l. 106--><p class="noindent" >There  is  a  relative  approximation  error  for  a
     given  bitwidth  in  <span 
class="ec-lmcsc-10">ieee  </span>754,  called  the  <span 
class="ec-lmri-10">machine</span>
     <span 
class="ec-lmri-10">epsilon</span>.<span class="footnote-mark"><a href="#fn13x0"><sup class="textsuperscript">13</sup></a></span><a  id="x1-4024f13"></a> 
     </p></li>
<li 
  class="enumerate" id="x1-4026x3">
     <!--l. 107--><p class="noindent" >Operations between numbers of diﬀerent magnitudes
     are particularly aﬀected by their relative numerical
     horizon.</p></li></ol>
<!--l. 110--><p class="noindent" ><span class="paragraphHead"><a  id="x1-5000"></a><span 
class="ec-lmbx-10">Variable precision and truncation error.</span></span>
   For most values of the exponent E, the diﬀerence between
two discrete values is determined by the absolute magnitude of
the signiﬁcand S. The diﬀerence between serial values is
\begin {align}  \Delta \texttt {S} &amp;= \texttt {␣000.0000.0000.0000.0000.0001}_{2} \nonumber \\ &amp; = 1.00000011920928955078125 - 1.0 \nonumber \\ &amp; = 0.00000011920928955078125 \nonumber \\ &amp; = 2^{-23}\textrm {.}  \end {align}
</p><!--l. 120--><p class="noindent" >This is multipled by the the result of the exponent E and the
bias, meaning that for each exponent value the diﬀerence
between subsequent values changes. (Figure <a href="#x1-50011">1<!--tex4ht:ref: fig:fp-res --></a>  represents this
schematically.)
</p>
   <figure class="figure"> 

                                                
                                                
<a  id="x1-50011"></a>
                                                
                                                
<!--l. 124--><p class="noindent" ><img class="full"
src="img/fp-res.png" alt="PIC"  
width="252" height="162"  />
</p>
<figcaption class="caption" ><span class="id">Figure 1:  </span><span  
class="content">Schematic  representation  of  granularity  and
variable   precision   of   ﬂoating-point   values   and   their
relationship to the (continuous) set of real numbers.</span></figcaption><!--tex4ht:label?: x1-50011 -->
                                                
                                                
   </figure>
<!--l. 129--><p class="indent" >   However, for normalized numbers, or numbers that are
left-shifted or right-shifted in order to carry out a calculation,
values are determined by the <span 
class="ec-lmri-10">relative shift </span>in exponent \(\Delta \texttt {E}\). For \(\texttt {E} = 2\),
for instance, the diﬀerence between serial values is \(2^{-21}\). This
variable precision means that the precision of ﬂoating-point
values varies across the range of representable numbers when
operations take place. Operations between two numbers of
fairly diﬀerent precisions are particularly vulnerable to
accuracy loss, although some numerical techniques can be
employed to mitigate.
</p><!--l. 132--><p class="indent" >   Truncation error results from terminating repeating
“binaries” (by analogy with “decimals”). Just as \(\frac {1}{3} = 0.\bar {3} = 0.3333\ldots {}\) has a ﬁnite
precision when written in base-10, numbers that are not
precise powers of two result in repeating fractions. These
necessarily terminate at the resolution of the signiﬁcand.
The number and nature of truncation and rounding can
signiﬁcantly aﬀect the accuracy of ﬂoating-point arithmetic
and algorithms (<a  id="x1-5002"></a> Izquierdo and Polhill, 2006).
</p>
<!--l. 134--><p class="noindent" ><span class="paragraphHead"><a  id="x1-6000"></a><span 
class="ec-lmbx-10">Machine epsilon.</span></span>
   The machine epsilon, or smallest value discernable from
1.0, is determined by the precision of the ﬂoating-point
representation. The machine epsilon for a particular bit width
is determined by setting two to the negative power of the
number of bits used for the magnitude of the mantissa
and accounting for the leading implicit bit 1; for 32-bit
single-precision ﬂoat this is \(2^{-{23-1}} = 2^{-22}\). Diﬀerences from 1.0 smaller than
this cannot be represented in this bit width.
</p>
<!--l. 138--><p class="noindent" ><span class="paragraphHead"><a  id="x1-7000"></a><span 
class="ec-lmbx-10">Sequence ordering.</span></span>
   In situations in which ﬂoating-point operations may
occur in diﬀerent orders, even the basic guarantee of
commutativity breaks. For instance, in 64-bit ﬂoating
point arithmetic, the following holds true (example in
                                                
                                                
Python):
</p>
   <!--l. 143-->
   <pre class="lstlisting" id="listing-2"><span class="label"><a  id="x1-7001r1"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">In</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[1]:</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(1.1-0.3)-0.8</span></span> 
<span class="label"><a  id="x1-7002r2"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">Out</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">[1]:</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">0.0</span></span> 
<span class="label"><a  id="x1-7003r3"></a></span> 
<span class="label"><a  id="x1-7004r4"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">In</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[2]:</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(1.1-0.8)-0.3</span></span> 
<span class="label"><a  id="x1-7005r5"></a><span 
class="ec-lmr-5">5</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">Out</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">[2]:</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">5.551115123125783</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">e</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">-17</span></span></pre>
   
<!--l. 151--><p class="noindent" >This occurs since operations of diﬀerent magnitude can aﬀect
the resulting signiﬁcand, a sort of horizon of resolution
leading to diﬀerences in the outcome. Sequence order
can be changed (and thus commutativity broken) as a
result of many common programmer design patterns,
including compiler optimizations, race conditions, and
parallelization.
</p><!--l. 154--><p class="indent" >   Another problem in numerical analysis, error accrual is
likewise due to the horizon of resolution. The accrual of
error due to summing sequences of numbers (whether in
parallel or serially) occurs in the summation of sequences of
numbers since the error term can grow as \(n\). Kahan–Babuška
compensated summation can be used to track a separate error
term (<span 
class="ec-lmri-10">de facto </span>extending the precision during the operations)
and adding it back in to the sum before yielding the ﬁnal
result (<a  id="x1-7006"></a> Kahan (1965), <a  id="x1-7007"></a> Babuška (1969)).
</p><!--l. 156--><p class="indent" >   Formally neither associative nor commutative for the above
reasons, ﬂoating-point arithmetic can break our mathematical
intuitions in interesting ways. However, this is a consistent
and well-understood phenomenon. For our purposes as
designers of deterministic computers, the most damning
indictment has to do not with <span 
class="ec-lmcsc-10">ieee </span>754 itself but with
manufacturer deviation in hardware implementation. In
1997, William Kahan himself complained (justly) about
the compromises inherent in the standard for compiler
implementers:
</p><!--l. 158--><p class="indent" >
     </p><blockquote class="quote">
     <!--l. 159--><p class="noindent" >Most  computer  linguists  ﬁnd  ﬂoating-point
     arithmetic   too   disruptive   [due   to]   [t]heir
     predilection  for  “referential  transparency”  ….
                                                
                                                
     Computer linguists also dislike functions with
     side-eﬀects and functions aﬀected by implicit
     variables  not  explicit  in  argument  lists.  But
     ﬂoating-point  operations  can  raise  <span 
class="ec-lmcsc-10">ieee  </span>754
     exception ﬂags as side-eﬀects, and operations
     are  aﬀected  implicitly  by  exception-handling
     and   rounding   modes   eligible   at   run-time
     according  to  <span 
class="ec-lmcsc-10">ieee  </span>754.  Alas,  that  standard
     omitted to bind ﬂags and modes to locutions
     in standard programming languages, and this
     omission grants computer linguists a licence for
     inaction. (<a  id="x1-7008"></a> Kahan, 1997)</p></blockquote>
<!--l. 162--><p class="indent" >   There are several sources of trouble for even single-threaded
deterministic computation using hardware <span 
class="ec-lmcsc-10">ieee </span>754 ﬂoating-point units
(<span 
class="ec-lmcsc-10">fpu</span>s):<span class="footnote-mark"><a href="#fn14x0"><sup class="textsuperscript">14</sup></a></span><a  id="x1-7009f14"></a> 
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-7012x1">
     <!--l. 165--><p class="noindent" >Optional, discretionary, or advisory aspects.
     </p></li>
<li 
  class="enumerate" id="x1-7014x2">
     <!--l. 166--><p class="noindent" >Gaps or omissions in the speciﬁcation.
     </p></li>
<li 
  class="enumerate" id="x1-7016x3">
     <!--l. 167--><p class="noindent" >Failure to implement the speciﬁcation exactly.
     </p></li>
                                                
                                                
<li 
  class="enumerate" id="x1-7018x4">
     <!--l. 168--><p class="noindent" >Out-of-sequence computations.</p></li></ol>
<!--l. 171--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-8000"></a><span 
class="ec-lmbx-10">Optional aspects.</span></span>
   Several aspects of <span 
class="ec-lmcsc-10">ieee </span>754 are optional or advisory,
including:
</p><!--l. 175--><p class="indent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-8002x1">
     <!--l. 176--><p class="noindent" >Exception handling means that the hardware may
     specify rounding via an overﬂow ﬂag.
     </p></li>
<li 
  class="enumerate" id="x1-8004x2">
     <!--l. 177--><p class="noindent" >Extended precisions formats are not a huge deal to
     leave out, but extended precision arithmetic (used for
     intermediate results) can materially change results.
     </p></li>
<li 
  class="enumerate" id="x1-8006x3">
     <!--l. 178--><p class="noindent" >Subnormals are optional;<span class="footnote-mark"><a href="#fn15x0"><sup class="textsuperscript">15</sup></a></span><a  id="x1-8007f15"></a> 
     some platforms may ﬂush them to zero or (worse)
     allow subnormal support to be disabled in certain
     cases.<span class="footnote-mark"><a href="#fn16x0"><sup class="textsuperscript">16</sup></a></span><a  id="x1-8008f16"></a> </p></li></ol>
                                                
                                                
<!--l. 181--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-9000"></a><span 
class="ec-lmbx-10">Omissions.</span></span>
   Whether something is a gap or optional is something
of a philosophical question for us, but some parts are
underspeciﬁed in a way that makes portability impossible.
E. g., mixed-precision operations can yield unpredictable
results depending on the compiler and hardware. This is a
function of rounding modes, precision loss, precision of
intermediate results, and the presence or absence of dedicated
hardware support for certain precision combinations.
</p>
<!--l. 185--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-10000"></a><span 
class="ec-lmbx-10">Inexact implementation.</span></span>
   Failure to implement <span 
class="ec-lmcsc-10">ieee </span>754 correctly may happen
inadvertently, as with the Pentium <span 
class="ec-lmcsc-10">fdiv </span>bug in the 1990s (<a  id="x1-10001"></a>
Edelman, 1997). Alternatively, chipset designers may deviate
from the speciﬁcation for reasons of performance or limitations
in the architecture.
</p><!--l. 189--><p class="indent" >   For instance, <span 
class="ec-lmcsc-10">ieee </span>754 deﬁnes a range of numbers as
“not-a-number” values, or NaNs. Per the speciﬁcation,
a NaN can be a signalling NaN, meaning that it
intends to ﬂag and possibly disrupt a problematic
computation;<span class="footnote-mark"><a href="#fn17x0"><sup class="textsuperscript">17</sup></a></span><a  id="x1-10002f17"></a> 
or a quiet NaN, which does not raise such an exception and
merely yields a result with the NaN propagated to the ﬁnal
result.<span class="footnote-mark"><a href="#fn18x0"><sup class="textsuperscript">18</sup></a></span><a  id="x1-10004f18"></a> 
Not all processors implement this part of <span 
class="ec-lmcsc-10">ieee </span>754 correctly:
                                                
                                                
“The Motorola <span 
class="ec-lmcsc-10">dsp563ccc </span>does not support NaNs or
inﬁnities. Floating-point arithmetic operations do not overﬂow
to inﬁnity; they saturate at the maximum representable value”
(Jones (2008), p. 338).
</p><!--l. 191--><p class="indent" >   As a further example, fused multiply-add (<span 
class="ec-lmcsc-10">fma</span>) (\(a \times b + c\)) is
implemented on certain hardware to favor double operations
and not quadruple-precision operations (<a  id="x1-10005"></a> Kahan (1997),
p. 5).
</p>
<!--l. 194--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-11000"></a><span 
class="ec-lmbx-10">Out-of-sequence computations.</span></span>
   A modern compiler using optimization ﬂags or even
modest parallelism can easily cause a ﬂoating-point calculation
to rely on operands that were produced in an order diﬀerent
than that speciﬁed in the code. This is largely opaque to the
programmer, aside from some simple heuristics, and makes it
diﬃcult to reproduce or reason about the ﬁne details of
computations.
</p><!--l. 198--><p class="indent" >   As demonstrated above, out-of-sequence or resequenced
computations can aﬀect results due to rounding behavior and
the “numerical horizon” which results between values. These
can happen due to multithreaded computation or an
optimizing compiler.
</p>
<!--l. 200--><p class="noindent" ><span class="paragraphHead"><a  id="x1-12000"></a><span 
class="ec-lmbx-10">Rounding mode.</span></span>
   <span 
class="ec-lmcsc-10">ieee </span>754 ﬂoating-point operations take place using one of
several rounding modes, for instance,
</p><!--l. 204--><p class="indent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-12002x1">
     <!--l. 205--><p class="noindent" >Round to nearest, ties to even. Set ties to the last bit
     as zero (even). The default.
     </p></li>
                                                
                                                
<li 
  class="enumerate" id="x1-12004x2">
     <!--l. 206--><p class="noindent" >Round   to   zero.   Truncate,   eﬀectively   rounding
     positive numbers down and negative numbers up.
     </p></li>
<li 
  class="enumerate" id="x1-12006x3">
     <!--l. 207--><p class="noindent" >Round   away   from   zero.   Truncate,   eﬀectively
     rounding positive numbers up and negative numbers
     down.
     </p></li>
<li 
  class="enumerate" id="x1-12008x4">
     <!--l. 208--><p class="noindent" >Round toward positive inﬁnity. Up regardless of sign.
     </p></li>
<li 
  class="enumerate" id="x1-12010x5">
     <!--l. 209--><p class="noindent" >Round toward negative inﬁnity. Down regardless of
     sign.</p></li></ol>
<!--l. 212--><p class="noindent" >The rounding mode can aﬀect the result of computations,
and if other processes are changing the mode (which
can even be set per-thread), results may not be reliably
reproducible.
</p><!--l. 215--><p class="indent" >   “Obtaining the correctly rounded result of an addition or
subtraction operation requires an additional bit in the
signiﬁcand (as provided by the <span 
class="ec-lmcsc-10">iec </span>60559 guard bit) to hold
the intermediate result” (<a  id="x1-12011"></a> Jones (2008), p. 65).
</p><!--l. 218--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a  id="x1-130003"></a>Urbit’s Implementation of IEEE 754</h3>
<!--l. 220--><p class="noindent" >Urbit implements a subset of <span 
class="ec-lmcsc-10">ieee </span>754 functionality in
<code class="lstinline"><span style="color:#000000">/sys/hoon</span></code>, the Hoon language speciﬁcation. The Nock
operations formally take place on integers. In practice,
                                                
                                                
we could imagine several ways of implementing such
operations: bitmasking the integers or breaking them
apart into three components, for instance. We take
Urbit’s implementation of <code class="lstinline"><span style="color:#000000">@rs</span></code> (single-precision ﬂoat) as
representative.<span class="footnote-mark"><a href="#fn19x0"><sup class="textsuperscript">19</sup></a></span><a  id="x1-13001f19"></a> 
</p><!--l. 222--><p class="indent" >   <code class="lstinline"><span style="color:#000000">++rs</span></code> is a wrapper core to instrument arithmetic arms like
<code class="lstinline"><span style="color:#000000">++add</span></code> using the <code class="lstinline"><span style="color:#000000">++ff</span></code> ﬂoating-point functionality core.
Ultimately this resolves to breaking out the components (sign,
exponent, and signiﬁcand) into separate numbers for the actual
operation.<span class="footnote-mark"><a href="#fn20x0"><sup class="textsuperscript">20</sup></a></span><a  id="x1-13002f20"></a> 
</p><!--l. 224--><p class="indent" >   The <code class="lstinline"><span style="color:#000000">++fn</span></code> core oﬀers a generalized interface for a superset
of <span 
class="ec-lmcsc-10">ieee </span>754-style ﬂoating-point implementations, permitting
bit width, precision, bias, and rounding mode to be freely
speciﬁed.<span class="footnote-mark"><a href="#fn21x0"><sup class="textsuperscript">21</sup></a></span><a  id="x1-13005f21"></a> 
The actual implementation on <code class="lstinline"><span style="color:#000000">+$fn</span></code>-typed values is rather
dense and features numerous rounding and overﬂow checks:
</p>
   <!--l. 227-->
   <pre class="lstlisting" id="listing-11"><span class="label"><a  id="x1-13006r1"></a></span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">++</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">add</span></span> 
<span class="label"><a  id="x1-13007r2"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">|=</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">a=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">e=@s</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a=@u</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">]</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">e=@s</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a=@u</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">]</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e=?</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">]</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">^-</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">fn</span></span> 
<span class="label"><a  id="x1-13008r3"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">=+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">q=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">dif:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e.a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e.b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13009r4"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">|-</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">?.</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">syn:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">q</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">$</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">q</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">+</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">q</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">))</span></span> 
<span class="label"><a  id="x1-13010r5"></a><span 
class="ec-lmr-5">5</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">?:</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e</span></span> 
<span class="label"><a  id="x1-13011r6"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">%f</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e.b</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">^add</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lsh</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[0</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">abs:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">q</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)]</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)]</span></span> 
<span class="label"><a  id="x1-13012r7"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">=+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">ma=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">met</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">0</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">mb=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">met</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">0</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)]</span></span> 
<span class="label"><a  id="x1-13013r8"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">=+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">^=</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">w</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">%+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">dif:si</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e.a</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">%-</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">sun:si</span></span> 
<span class="label"><a  id="x1-13014r9"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">?:</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">gth</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">prc</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">ma</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">^sub</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">prc</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">ma</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">0</span></span> 
<span class="label"><a  id="x1-13015r10"></a><span 
class="ec-lmr-5">10</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">=+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">^=</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">%+</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">sum:si</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e.b</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">sun:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">mb</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13016r11"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">?:</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">=</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">((</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">cmp:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">w</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">--1</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13017r12"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">?-</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">r</span></span> 
<span class="label"><a  id="x1-13018r13"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%z</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lug</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%fl</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%d</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lug</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%fl</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13019r14"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%a</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lug</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%lg</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%u</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lug</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%lg</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13020r15"></a><span 
class="ec-lmr-5">15</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%n</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lug</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">%na</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-13021r16"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtk-10x-x-90">==</span></span> 
<span class="label"><a  id="x1-13022r17"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">rou</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">e.b</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">^add</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">lsh</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">[0</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">abs:si</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">q</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)]</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a.b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)])</span></span></pre>
   
<!--l. 247--><p class="indent" >   There is, of course, a feint in the foregoing discussion. Nock
is a virtual machine speciﬁcation, and in practice operations
that would beneﬁt from more direct expression in C are
<span 
class="ec-lmri-10">jetted</span>.<span class="footnote-mark"><a href="#fn22x0"><sup class="textsuperscript">22</sup></a></span><a  id="x1-13023f22"></a>  Thus the
                                                
                                                
actual call in this case will correspond to some C code using the SoftFloat
library:<span class="footnote-mark"><a href="#fn23x0"><sup class="textsuperscript">23</sup></a></span><a  id="x1-13024f23"></a> 
</p>
   <!--l. 250-->
   <pre class="lstlisting" id="listing-12"><span class="label"><a  id="x1-13025r1"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">u3_noun</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3qet_add</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">u3_atom</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3_atom</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3_atom</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">r</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">{</span></span> 
<span class="label"><a  id="x1-13026r2"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">union</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">sing</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">d</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">;</span></span> 
<span class="label"><a  id="x1-13027r3"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">//</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">set</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">IEEE</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">754</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">rounding</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">mode</span></span> 
<span class="label"><a  id="x1-13028r4"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">_set_rounding</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">r</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">);</span></span> 
<span class="label"><a  id="x1-13029r5"></a><span 
class="ec-lmr-5">5</span></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">//</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">unwrap</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">nouns</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">into</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">C</span></span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">-</span></span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">typed</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">values</span></span> 
<span class="label"><a  id="x1-13030r6"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3r_word</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(0,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">);</span></span> 
<span class="label"><a  id="x1-13031r7"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">d</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3r_word</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(0,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">);</span></span> 
<span class="label"><a  id="x1-13032r8"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">//</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">perform</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">addition</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">and</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">unify</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">NaN</span></span> 
<span class="label"><a  id="x1-13033r9"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">e</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">s</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">_nan_unify</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">f32_add</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">s</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">d</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">s</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">));</span></span> 
<span class="label"><a  id="x1-13034r10"></a><span 
class="ec-lmr-5">10</span></span> 
<span class="label"><a  id="x1-13035r11"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">//</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">wrap</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">C</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">value</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">back</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">into</span></span><span style="color:#404040"> </span><span style="color:#404040"><span 
class="ec-lmtti-10x-x-90">noun</span></span> 
<span class="label"><a  id="x1-13036r12"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">return</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">u3i_words</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(1,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0026;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">e</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">c</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">);</span></span> 
<span class="label"><a  id="x1-13037r13"></a></span><span style="color:#000000"><span 
class="ec-lmtt-9">}</span></span></pre>
   
<!--l. 266--><p class="indent" >   Why SoftFloat? Enter, stage left, the problem of
platform-portable determinism.
</p>
   <h3 class="sectionHead"><span class="titlemark">4   </span> <a  id="x1-140004"></a>Deterministic Computation with a <br 
class="newline" />Fractional Part</h3>
<!--l. 271--><p class="noindent" >Non-real arithmetic is less signiﬁcant for many of the core
operations of Urbit as a personal server platform. However,
gaming, machine learning, graphics, and other applications rely on
ﬂoating-point calculations—preferably as fast as possible. In fact,
not only applications-oriented processes rely on determinism:
guarantees in cryptography and contractual correctness for web3;
veriﬁcation and validation; accounting and legal compliance;
and code correctness analysis all require reproducible
determinism.<span class="footnote-mark"><a href="#fn24x0"><sup class="textsuperscript">24</sup></a></span><a  id="x1-14001f24"></a> 
</p><!--l. 273--><p class="indent" >   Why can’t we just allow diﬀerent results in the last binary
places of the signiﬁcand? Philosophically, Urbit holds to the
following statements (<a  id="x1-14002"></a> <code>~wicdev-wisryt</code>, 2020):
     </p><ol  class="enumerate1" >
                                                
                                                
<li 
  class="enumerate" id="x1-14004x1">
     <!--l. 276--><p class="noindent" >A10.    Correctness    is    more    important    than
     performance.
     </p></li>
<li 
  class="enumerate" id="x1-14006x2">
     <!--l. 277--><p class="noindent" >A12. Correctness is more important than optimality.
     </p></li>
<li 
  class="enumerate" id="x1-14008x3">
     <!--l. 278--><p class="noindent" >A14. Deterministic beats heuristic.
     </p></li>
<li 
  class="enumerate" id="x1-14010x4">
     <!--l. 279--><p class="noindent" >F1. If it’s not deterministic, it isn’t real.</p></li></ol>
<!--l. 282--><p class="noindent" >Urbit makes much of avoiding the “ball of mud” “standard
software architecture” (<a  id="x1-14011"></a> Foote and Yoder, 1999). In this
design anti-pattern, a lack of guarantees and predictable
behavior leads <span 
class="ec-lmri-10">inevitably </span>to haphazard and illegible software
bloat. We can thus understand why Urbit as a platform
considers even deviations in the last bit of a signiﬁcand to
be threads fraying the edge of sanity (<a  id="x1-14012"></a> <code>~wicdev-wisryt</code>,
2020):
     </p><blockquote class="quote">
     <!--l. 286--><p class="noindent" >If you do the same thing twice, your computer
     should react the same way. This is comforting.
     This is also what makes it easy to reason about
     and use eﬀectively. If you’re not sure what your
     computer will do, you’ll be afraid of it and act
     defensively toward it. This inevitably leads to
     a big ball of mud.</p></blockquote>
                                                
                                                
<!--l. 289--><p class="indent" >   For most purposes in the broader software world,
tightly reproducible precision has not been a high priority.
Precision having already been sacriﬁced, the gist of the
calculation is more important than the fourth decimal place
(e. g. in realtime 3D graphics). This leads to the phrase
“implements the <span 
class="ec-lmcsc-10">ieee </span>754 standard” being interpreted
erroneously to imply full reproducibility (<a  id="x1-14013"></a> Figueroa del Cid,
2000).
</p><!--l. 291--><p class="indent" >   For example, consider the expression \((a \times b) + c\). If a compiler
permits the two operations to be evaluated sequentially (a
multiplication followed by an addition), then rounding occurs
twice. If a compiler optimizes the operation into an <span 
class="ec-lmcsc-10">fma</span>, or
fused multiply-add, then a single rounding occurs. <a  id="x1-14014"></a> Peters
presents a pathological case for 32-bit single-precision
ﬂoating-point values: \(a = 1.00000011920929\), \(b = 53400708\), and \(c = -b\). In this case, the two-stage
operation wipes out the \(0.00000011920929\) component of \(a\), yielding \(a\) as an
integer. Then \(c\) is added and the result is \(8\). With <span 
class="ec-lmcsc-10">fma </span>as a
single-step operation, the (correct) answer \(6.365860462\) is obtained. The
optimization is more correct than the naïve route in this
case.
</p><!--l. 293--><p class="indent" >   However, in another example due to <a  id="x1-14015"></a> Dawson, <span 
class="ec-lmcsc-10">fma </span>yields
incorrect results: for \(a \times b + c \times d\) with \(a = c\) and \(b = -d\), the answer should be zero,
and calculated in two steps will typically be zero. With a fused
multiply-add, however, the code becomes fmadd(a, b, c*d),
rounding the multiplication of \(c\) and \(d\) but not that of \(a\) and \(b\); the
answer will likely not be zero.
</p><!--l. 295--><p class="indent" >   The situation grows more ambiguous across architectures. <a  id="x1-14016"></a>
Jones (2008), p. 346, presents the pathological case of a
compliant platform that may use extended precision bits in
the calculation of a + b:
</p><!--l. 297--><p class="indent" >
                                                
                                                
</p>
   <!--l. 299-->
   <pre class="lstlisting" id="listing-13"><span class="label"><a  id="x1-14017r1"></a></span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">#</span></span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">include</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x003C;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">stdio</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">.</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">h</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x003E;</span></span> 
<span class="label"><a  id="x1-14018r2"></a></span> 
<span class="label"><a  id="x1-14019r3"></a></span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">extern</span></span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">double</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">,</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">;</span></span> 
<span class="label"><a  id="x1-14020r4"></a></span> 
<span class="label"><a  id="x1-14021r5"></a><span 
class="ec-lmr-5">5</span></span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">void</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">f</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">void</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">{</span></span> 
<span class="label"><a  id="x1-14022r6"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">double</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">;</span></span> 
<span class="label"><a  id="x1-14023r7"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">+</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">;</span></span> 
<span class="label"><a  id="x1-14024r8"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#404040"><span 
class="ec-lmtk-10x-x-90">if</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">!=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">+</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">)</span></span> 
<span class="label"><a  id="x1-14025r9"></a></span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">printf</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">(</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0022;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">x</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">!=</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">a</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">+</span></span><span style="color:#000000"> </span><span style="color:#000000"><span 
class="ec-lmtt-9">b</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">\</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">n</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">&#x0022;</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">);</span></span> 
<span class="label"><a  id="x1-14026r10"></a><span 
class="ec-lmr-5">10</span></span><span style="color:#000000"><span 
class="ec-lmtt-9">}</span></span></pre>
   
<!--l. 312--><p class="noindent" >In this hypothetical case, “any extended precision bits will be
lost in the ﬁrst calculation of a+b when it is assigned
to x. The result of the second calculation of a+b may
be held in a working register at the extended precision
and potentially contain additional value bits not held
in x, the result of the equality test then being false.” <a  id="x1-14027"></a>
Higham (2002) provides further examples of pathological
cases.
</p><!--l. 315--><p class="indent" >   K&#x0026;R C permitted the compiler to re-order ﬂoating-point
expressions by associativity, which could run afoul of our
limitations. <span 
class="ec-lmcsc-10">ansi </span>C (C89), recognizing the issue introduced
by this innocuous change, forbade such re-ordering (<a  id="x1-14028"></a>
MacDonald, 1991). Compiler optimizations (e. g. <span 
class="ec-lmcsc-10">gcc</span>’s
-O3) can bypass this restriction, once again breaking
determinism;<span class="footnote-mark"><a href="#fn25x0"><sup class="textsuperscript">25</sup></a></span><a  id="x1-14029f25"></a> 
for instance, ﬂoating-point operations can be pipelined,
leading to out-of-order execution.
</p><!--l. 317--><p class="indent" >   The ﬂy in the ointment for Urbit’s deterministic computing
is that jet-accelerated Nock equivalents must reliably produce
the same results (both to each other and to Nock) regardless
of the runtime on which it is being evaluated. Thus even small
irregularities in ﬂoating-point implementations have macroscopic
ramiﬁcations for deterministic computing. Any guarantee broken
breaks them all, just as it would for a formal correctness
proof.<span class="footnote-mark"><a href="#fn26x0"><sup class="textsuperscript">26</sup></a></span><a  id="x1-14030f26"></a> 
</p><!--l. 319--><p class="indent" >   The challenge of the lack of determinacy for certain critical
applications has been acknowledged before, such as by James
                                                
                                                
Demmel and the ReproBLAS team (<a  id="x1-14031"></a> Demmel et al. (2017), <a  id="x1-14032"></a>
Ahrens, Nguyen, and Demmel (2018)) and by <a  id="x1-14033"></a> Dawson.
Dawson makes much of the eﬀect of rounding modes and the
option to disable subnormals, both of which would have major
eﬀects on computational reproducibility. The situation is
worse for transcendental functions, because there is necessarily
truncation and/or rounding error (Dawson, 2013). Even
conversion between bases for output and input is not
necessarily reproducible, as Dawson continues: “Doing perfect
conversions eﬃciently was an unsolved problem when
the original <span 
class="ec-lmcsc-10">ieee </span>standard came out, and while it has
since been solved, this doesn’t mean that everybody
does correctly rounded printing.” <a  id="x1-14034"></a> Koenig (2018) expend
much eﬀort on the problem of computing a dot product
exactly in hardware, given the contingencies of multicore
processors.<span class="footnote-mark"><a href="#fn27x0"><sup class="textsuperscript">27</sup></a></span><a  id="x1-14035f27"></a> 
</p><!--l. 321--><p class="indent" >   The ﬁeld of debate for possible solutions for implementing
ﬂoating-point arithmetic which is portable across platforms
includes:
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-14037x1">
     <!--l. 324--><p class="noindent" >Hardware-supported ﬂoating-point arithmetic.
     </p></li>
<li 
  class="enumerate" id="x1-14039x2">
     <!--l. 325--><p class="noindent" >Software-deﬁned ﬂoating-point library.
     </p></li>
                                                
                                                
<li 
  class="enumerate" id="x1-14041x3">
     <!--l. 326--><p class="noindent" >Opaque calculations.
     </p></li>
<li 
  class="enumerate" id="x1-14043x4">
     <!--l. 327--><p class="noindent" >Stored results.
     </p></li>
<li 
  class="enumerate" id="x1-14045x5">
     <!--l. 328--><p class="noindent" >Proscribing <span 
class="ec-lmcsc-10">ieee </span>754.</p></li></ol>
<!--l. 331--><p class="indent" >   We consider each in turn, with its ramiﬁcations for a
deterministic computing platform and in particular its
prospects for adoption in Nock-based systems.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.1   </span> <a  id="x1-150004.1"></a>Hardware-supported ﬂoating-point arithmetic</h4>
<!--l. 335--><p class="noindent" >As outlined above, execution of code-equivalent ﬂoating-point
computations produced from source by diﬀerent compilers
on diﬀerent hardware architectures may lead to small
diﬀerences in outcome, non-negligible for a deterministic
computer. Thus, for this and a constellation of related
reasons, hardware-supported ﬂoating-point arithmetic
seems to be <span 
class="ec-lmri-10">prima facie </span>unviable for deterministic
                                                
                                                
computing.<span class="footnote-mark"><a href="#fn28x0"><sup class="textsuperscript">28</sup></a></span><a  id="x1-15001f28"></a> 
</p><!--l. 337--><p class="indent" >   We do not know the ﬁeld of possible future
hardware architectures which Nock as a deterministic
computing platform may be called upon to
execute.<span class="footnote-mark"><a href="#fn29x0"><sup class="textsuperscript">29</sup></a></span><a  id="x1-15002f29"></a> 
Jet-accelerated code should be intelligently robust about its
the hardware, but Hoon and Nock code should be completely
agnostic to the hardware.
</p><!--l. 339--><p class="indent" >   That’s the problem. What are some possible hardware-targeted
solutions?
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-15004x1">
     <!--l. 342--><p class="noindent" >Control  the  compiler  and  runtime  stack  top  to
     bottom.
     </p></li>
<li 
  class="enumerate" id="x1-15006x2">
     <!--l. 343--><p class="noindent" >Store  a  hardware  and  compiler  tag  and  simulate
     when not on that platform.
                                                
                                                
     </p></li>
<li 
  class="enumerate" id="x1-15008x3">
     <!--l. 344--><p class="noindent" >Support only a single hardware for the lifetime of a
     ship.
     </p></li>
<li 
  class="enumerate" id="x1-15010x4">
     <!--l. 345--><p class="noindent" >Dock ﬂoating-point results.
     </p></li>
<li 
  class="enumerate" id="x1-15012x5">
     <!--l. 346--><p class="noindent" >Check consistency of results.</p></li></ol>
   <h5 class="subsubsectionHead"><span class="titlemark">4.1.1   </span> <a  id="x1-160004.1.1"></a>Control the stack</h5>
<!--l. 351--><p class="noindent" >If you controlled the compiler and runtime execution stack to
a suﬃcient degree, could you yield deterministic ﬂoating-point
arithmetic from the hardware? “A translator that generates
very high performance code is of no use if the ﬁnal behavior is
incorrect” (<a  id="x1-16001"></a> Jones (2008), p. 189); that is, optimizations often
come at the cost of correctness.
</p><!--l. 353--><p class="indent" >   To start oﬀ, what must be considered part of the stack in
this sense? At a minimum, the compiler and linker toolchain
(including ﬂags and options) and the actual runtime must be
included. (This explicitly introduces a dependence between
Martian software and Earthling software, repugnant to the
Urbit ethos.)
</p><!--l. 355--><p class="indent" >   We also must decide what the target is. Do we aim
for the most portable conﬁguration (as determined by
number of consumer or enterprise users)? Do we aim for the
“closest” to <span 
class="ec-lmcsc-10">ieee </span>754 adherence? Do we aim for simplicity, or
compilation speed, or any of a half-dozen other optimizable
variables?
</p><!--l. 357--><p class="indent" >   For instance, suppose that one intended to use the C keyword
volatile to block certain common optimizations on a ﬂoating-point
                                                
                                                
value.<span class="footnote-mark"><a href="#fn30x0"><sup class="textsuperscript">30</sup></a></span><a  id="x1-16002f30"></a> 
The runtime at the level of Nock does not know if a value is
considered ﬂoating-point or not. At the level of a jet, the use
of volatile can correctly bar certain hardware optimizations,
but these need to be carefully enumerated and understood in
the light of the other toolchain concerns enumerated in this
section. Strictly speaking, volatile only seeks to guarantee that
stale calculations are not inadvertently reused due to
optimization. Without hardware optimization, the utility of an
[<span 
class="ec-lmcsc-10">fpu</span>] for fast ﬂoating-point computations is questionable. The
risk of a jet mismatch remains high, as does a nonportable
jet.<span class="footnote-mark"><a href="#fn31x0"><sup class="textsuperscript">31</sup></a></span><a  id="x1-16003f31"></a> 
</p><!--l. 359--><p class="indent" >   Can the C-deﬁned ﬂoating-point environment (as supplied by
fenv.h) answer to this need? This aﬀords the ability to specify
not only rounding modes and access ﬂoating-point exception
status ﬂags, but it is not clear whether this environmental
control portably spans the entire output of ﬂoating-point
                                                
                                                
computations.<span class="footnote-mark"><a href="#fn32x0"><sup class="textsuperscript">32</sup></a></span><a  id="x1-16004f32"></a> 
</p><!--l. 361--><p class="indent" >   Finally, “[a]n implementation is not required to provide a
facility for altering the modes for translation-time arithmetic,
or for making exception ﬂags from the translation available to
the executing program” (<a  id="x1-16006"></a> Jones (2008), p. 200). The
information we purport to gain by controlling the stack in the
manner above outlined is possibly not even available to the
compiler and the runtime executable.
</p><!--l. 363--><p class="indent" >   We suggest that deterministically correct stack control
in the sense we have described here is impossible for
an arbitrary conﬁguration of the modern hardware
stack.<span class="footnote-mark"><a href="#fn33x0"><sup class="textsuperscript">33</sup></a></span><a  id="x1-16007f33"></a> 
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">4.1.2   </span> <a  id="x1-170004.1.2"></a>Simulate the hardware</h5>
<!--l. 367--><p class="noindent" >If you knew what the compiler and execution stack behavior
looked like when a calculation was performed, could you
reproduce it in software at need on a diﬀerent platform?
</p><!--l. 369--><p class="indent" >   Hardware simulation faces some diﬃculties in the
same vein as controlling the stack. The proposal yields a
combinatorial explosion when considering the combinations of
hardware chips, compilers, and compiler ﬂags. Nor is it clear
that hardware documentation can be accrued in suﬃcient
quantity and detail to guarantee the success of such a
project.
</p><!--l. 371--><p class="indent" >   The Urbit runtime provides an epoch system, meaning
that the event log is separated into snapshots and subsequent
                                                
                                                
events (<a  id="x1-17001"></a> <code>~mastyr-bottec</code>, 2023). This is currently used to
monitor the use of old binaries which could potentially have a
jet mismatch. It would be moderately straightforward to
extend this functionality to record the compilation ﬂags and
architecture of that Vere binary, which could be useful in
event playback. However, this remains an unsatisfactory
solution because it would lead to Urbit runtime instances
intentionally producing diﬀerent code (rather than a jet
mismatch which would require correction).
</p><!--l. 373--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">4.1.3   </span> <a  id="x1-180004.1.3"></a>Support a single hardware platform</h5>
<!--l. 375--><p class="noindent" >
     </p><blockquote class="quote">
     <!--l. 376--><p class="noindent" >Marriage is a ﬁne institution, but I’m not ready
     for an institution. (Mae West)</p></blockquote>
<!--l. 379--><p class="noindent" >A permanent commitment to a single hardware platform—either
for the Urbit platform as a whole or for a particular running
instance—could solve the determinism problem. This
conﬁguration would be tenable for single-purpose ships with
lifetime control (likely moons or comets), but inconvenient for
the “hundred-year computer” model touted for planets and
superior ranks in Urbit.
</p><!--l. 381--><p class="indent" >   To make a lifelong commitment to a particular hardware
platform when the lifetime of a deterministic computer is
unknown is therefore deemed foolhardy.
</p><!--l. 383--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">4.1.4   </span> <a  id="x1-190004.1.4"></a>Dock ﬂoating-point results</h5>
<!--l. 385--><p class="noindent" >What about trimming ﬂoating-point values of their least
signiﬁcant bits? When would this take place—at each step of a
multi-step computation? At the level of single-bit rounding
                                                
                                                
errors, this would potentially work, and amounts to selecting
a rounding mode towards even (last digit 0). Accrual
across multiple calculations could potentially render this
unreliable, particularly if diﬀerent computational paths are
supposed to lead to the same result and do not as a result of
docking.
</p><!--l. 387--><p class="indent" >   One could also envision docking more than the last bit.
This introduces a step to check and adjust the ﬂoating-point
value, and in addition breaks <span 
class="ec-lmcsc-10">ieee </span>754 compliance—at which
point the trouble of trying to reconcile <span 
class="ec-lmcsc-10">ieee </span>754 with
determinism fails.
</p><!--l. 389--><p class="indent" >   In general, we cannot assign a high degree of signiﬁcance
to ﬁgures beyond the ﬁrst few, but accruals across large
data sets (such as large language models) can become
signiﬁcant (as attested to by the need for compensated
summation).
</p><!--l. 391--><p class="indent" >   A related technique could pack bits of larger ﬂoating-point
values into smaller ones, but this is functionally a software-deﬁned
solution (see, e. g., <a  id="x1-19001"></a> Brun (2018)).
</p><!--l. 393--><p class="noindent" >
</p>
   <h5 class="subsubsectionHead"><span class="titlemark">4.1.5   </span> <a  id="x1-200004.1.5"></a>Consistency checks</h5>
<!--l. 395--><p class="noindent" >Another option is to compare Nock and jet code for every
computation and only accept the C code if it is “correct”.
This immediately runs into a very undesirable characteristic:
every ﬂoating-point calculation is run twice, obviating at least
one calculation and destroying any eﬃciency gains from
jetting the code.
</p><!--l. 397--><p class="indent" >   One could cache ﬂoating-point computations somewhere in the
system.<span class="footnote-mark"><a href="#fn34x0"><sup class="textsuperscript">34</sup></a></span><a  id="x1-20001f34"></a> 
This is liable to become prohibitively large for systems as
every individual ﬂoating point calculation of all time becomes
archived against future need.
                                                
                                                
</p><!--l. 399--><p class="indent" >   We conclude that, at the current time, naïve
hardware-deﬁned ﬂoating point is not viable for deterministic
systems.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.2   </span> <a  id="x1-210004.2"></a>Software-deﬁned ﬂoating-point library</h4>
<!--l. 403--><p class="noindent" >In the absence of a dedicated ﬂoating-point unit (<span 
class="ec-lmcsc-10">fpu</span>)
and ﬂoating-point assembly instructions, ﬂoating-point
computations are carried out in software. The type can be
decomposed from bits, operated on, then packed back into
the single type of appropriate value. For instance, prior
to the widespread advent of 64-bit consumer hardware,
applications that needed double values on 32-bit PC
architecture utilized software emulation using two 32-bit
numbers together.
</p><!--l. 405--><p class="indent" >   Urbit’s current solution for ﬂoating-point computation is
to utilize a software-deﬁned ﬂoating-point library, the
SoftFloat library by <a  id="x1-21001"></a> Hauser. SoftFloat is an implementation
in software of a subset of <span 
class="ec-lmcsc-10">ieee </span>754 for ﬁve ﬂoating-point
types.<span class="footnote-mark"><a href="#fn35x0"><sup class="textsuperscript">35</sup></a></span><a  id="x1-21002f35"></a> 
Urbit statically links the library into its runtime binary so it is
always available for Nock to utilize as a jet.
</p><!--l. 407--><p class="indent" >   While formally correct, software FP is slower than
hardware ﬂoating point, and likely prohibitively slow for many
large matrix applications such as <span 
class="ec-lmcsc-10">llm</span>s. (“Correctness is more
important than performance.”) Performance is the dolorous
stroke against software-deﬁned ﬂoating point. (On the other
hand, some early versions of the Apple–<span 
class="ec-lmcsc-10">ibm</span>–Motorola
PowerPC <span 
class="ec-lmcsc-10">risc </span>architecture did not have dedicated
hardware ﬂoating-point units (<span 
class="ec-lmcsc-10">fpu</span>s) or ﬂoating-point
assembler instructions at all, requiring full software
                                                
                                                
implementation.<span class="footnote-mark"><a href="#fn36x0"><sup class="textsuperscript">36</sup></a></span><a  id="x1-21003f36"></a> )
<span 
class="ec-lmcsc-10">gcc </span>has supported a software ﬂoating-point mode using
fp-bit.c (<a  id="x1-21005"></a> <span 
class="ec-lmcsc-10">gnu </span>Project, 2008); this was particularly used to
accommodate the PowerPC limitations rather than to
provide either speed or determinism (cf. <a  id="x1-21006"></a> Sidwell and Myers
(2006)).
</p><!--l. 409--><p class="indent" >   An optimized portable deterministic software library for
ﬂoating-point calculations may be a suﬃciently fast solution
to meet Urbit’s needs even for vector computations. A
diﬀerent avenue worthy of investigation is to take <span 
class="ec-lmcsc-10">ieee </span>754
compliant ﬂoating-point values as inputs and outputs, then
transform into a local representation for an optimized
portable deterministic calculation. For instance, <a  id="x1-21007"></a> Thall
(2007) presents the concept of “unevaluated sums”, a
generalized technique for accruing error in situations where
additional precision is necessary for accuracy. However, even
with an agreed-upon standard library like SoftFloat, it is
important to keep in mind that exact ﬂoating-point results for
transcendental functions are still not correctly known in many
cases.<span class="footnote-mark"><a href="#fn37x0"><sup class="textsuperscript">37</sup></a></span><a  id="x1-21008f37"></a> 
This particular poses a problem for functions like \(\sin \) which may
be calculated by diﬀerent routes in Hoon/Nock and in
C/Rust. For the time being, we conclude that Urbit’s
discipline requires only using Hoon/Nock implementations of
transcendental functions.
                                                
                                                
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.3   </span> <a  id="x1-220004.3"></a>Opaque calculations</h4>
<!--l. 413--><p class="noindent" >When a request for data is made over the network, one is not
certain what the resulting data will be. Their value is
epistemically opaque. In Urbit’s event log, the results of
network calls are persisted as eﬀects in the modiﬁed state (for
successful events).
</p><!--l. 415--><p class="indent" >   What if Urbit treated a call that had a ﬂoating-point
computation as if it were a network call, that is, as if it were a
referentially opaque injection into Urbit’s state? One
diﬀerence is that network calls result as side eﬀects from hints
to the runtime which then handles the plumbing, as it were,
and injects the resulting gift task back into Arvo as if a <span 
class="ec-lmri-10">deus</span>
<span 
class="ec-lmri-10">ex machina</span>, from Arvo’s perspective. (It should of course
know how to handle such a contingency.) There are two main
objections that can be made here:
</p><!--l. 417--><p class="indent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-22002x1">
     <!--l. 418--><p class="noindent" >From    the    programmer’s    standpoint,    every
     ﬂoating-point computation would need to be bundled
     as if it were a network call, and the result treated as if
     it were a new move passed back into the kernel. This
     destroys  synchronicity  and  changes  ﬂoating-point
     computations from lightweight programmer choices
     into heavy and occasional calls.
     </p></li>
<li 
  class="enumerate" id="x1-22004x2">
     <!--l. 420--><p class="noindent" >The storage of every result of every ﬂoating-point
     computation could become prohibitively large. Work
     on large matrices in numerical analysis or machine
     learning  could  rapidly  balloon  the  event  log  since
     every intermediate state would also become part of
     the ship’s immutable history.</p></li></ol>
                                                
                                                
<!--l. 423--><p class="indent" >   To the ﬁrst objection, we can point to the current design
pattern utilized in scrying (or the request for values from
the bound scry namespace). Local scry values (such as
values exposed by a system service or vane) are accessed
synchronously using the <code class="lstinline"><span style="color:#000000">.^</span></code> dotket operator. This is
straightforward and easy to integrate into a program.
Remote scry values must be requested asynchronously from
another ship, and return at an indeterminate future time as
<code class="lstinline"><span style="color:#000000">gift</span></code>s to be processed in another part of the vane or
application.
</p><!--l. 425--><p class="indent" >   To the second, we observe that although Urbit is a state
machine whose history is part of its state, in practice we can
mitigate event log growth by either <span 
class="ec-lmri-10">chopping </span>the event log by
storing its state and permitting replay forward from that point
or <span 
class="ec-lmri-10">tombstoning </span>data which should never be available
again.<span class="footnote-mark"><a href="#fn38x0"><sup class="textsuperscript">38</sup></a></span><a  id="x1-22005f38"></a> 
</p><!--l. 427--><p class="indent" >   In a successful implementation of this scenario, one could
imagine distinguishing slower software execution (treated
synchronously) from faster hardware acceleration (treated
asynchronously).
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.4   </span> <a  id="x1-230004.4"></a>Stored results</h4>
<!--l. 432--><p class="noindent" >Instead of repeating computations that have been made in the
past, what if we cached the result of all of them, so that any
new computations with the same values are guaranteed to
result in the same value via a cache lookup instead of a
calculation? Urbit uses memoization frequently in Arvo and in
the runtime, so this is an aesthetically compatible option; we
consider its feasibility.
</p><!--l. 434--><p class="indent" >
     </p><blockquote class="quote">
                                                
                                                
     <!--l. 435--><p class="noindent" >A  recently  proposed  hardware  acceleration
     technique  is  to  store  the  results  of  previous
     multiplication   and   division   operations   in
     a  cache,  reusing  rather  than  recalculating
     the   result   whenever   possible.   (Dynamic
     proﬁling  has  found  that  a  high  percentage
     of these operations share the same operands
     as   previous   operations.)   (<a  id="x1-23001"></a>   Jones   (2008),
     p. 1148)<span class="footnote-mark"><a href="#fn39x0"><sup class="textsuperscript">39</sup></a></span><a  id="x1-23002f39"></a> </p></blockquote>
<!--l. 438--><p class="indent" >   On Urbit, this introduces an \(O(1)\) average-case/\(O(n)\) worst-case
cache lookup from a MurmurHash3 hash key calculation (what
Urbit calls a <code class="lstinline"><span style="color:#000000">++mug</span></code>). This must be weighed against the
ﬂoating-point algorithm in consideration, as well as what is
actually hashed (likely the Nock of the calculation contained
in the dynamic hint).
</p><!--l. 440--><p class="indent" >   This bears some similarities to aspects of the network call
suggestion above, in that the second objection to that one
holds here. Event log and state bloat (via the cache) are
liabilities. Such a cache would be a feature of the Arvo
instance, not the runtime VM. Unlike a truncated event log,
the cache must be a permanent feature of the ship’s state
rather than a convenience.
</p><!--l. 442--><p class="indent" >   “Storing results” could also be met by the use of
<span 
class="ec-lmcsc-10">sparc</span>-style logging. In that hardware platform, suspicious
computations are ﬂagged and hashed into a lookup table
by site in the originating program. Such events are
logged not by timestamp or by computation hash but
by callsite in the originating program (<a  id="x1-23004"></a> Kahan (1997),
p. 6).<span class="footnote-mark"><a href="#fn40x0"><sup class="textsuperscript">40</sup></a></span><a  id="x1-23005f40"></a> 
Sun implemented this in <span 
class="ec-lmcsc-10">sparc </span>for “retrospective diagnostics”
but the technique could allow a more lapidary operation for
Urbit. (Follow-on considerations include whether such
computations should now be considered “bound” in a sense
                                                
                                                
like that of the scry namespace.)
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.5   </span> <a  id="x1-240004.5"></a>Proscribing IEEE 754</h4>
<!--l. 446--><p class="noindent" >What if the Scylla of <span 
class="ec-lmcsc-10">ieee </span>754 is avoided for some Charybdis?
We can approach this solution space at two levels: either by
sector or entirely.
</p>
<!--l. 448--><p class="noindent" ><span class="paragraphHead"><a  id="x1-25000"></a><span 
class="ec-lmbx-10">Proscribe by sector.</span></span>
   One solution to the speed-vs.-reproducibility dilemma is to
permit hardware-accelerated <span 
class="ec-lmcsc-10">ieee </span>754 operations, but only in
a veriﬁed subset permissible for jets. This would require
careful vetting of the hardware stack and compiler options to
deﬁne a permissible subset of <span 
class="ec-lmcsc-10">ieee </span>754 operations as “known
good”. Coupled with the epoch system, it may be a feasible
solution.
</p><!--l. 452--><p class="indent" >   What degree of vetting will reliably answer the gap
between <span 
class="ec-lmcsc-10">ieee </span>754 and hardware implementation for any
particular operation? (<a  id="x1-25001"></a> Jones (2008), pp. 330ﬀ.) and <a  id="x1-25002"></a>
Goldberg (1991) provide a careful analysis of accuracy errors
inherent to <span 
class="ec-lmcsc-10">ieee </span>754 as a standard, but due to the variety of
possible scenarios do not treat of real compilers and chipsets
much.<span class="footnote-mark"><a href="#fn41x0"><sup class="textsuperscript">41</sup></a></span><a  id="x1-25003f41"></a> 
Trivially, as demonstrated above in the Python example, \((a + b) + c \neq a + (b + c)\), and
even modest reordering of operations by a zealous compiler
optimization is susceptible of introducing nonportable and
thus nondeterministic (in our sense) behavior.
</p><!--l. 454--><p class="indent" >   Having identiﬁed an appropriate subset of operations, we
may imagine that the use of #ifdef, Autotools’ conﬁgure, and
a jetting library may answer to our need. Any jet library
would have to be carefully constructed to avoid imposing
tight discipline directly on the end user (modal Hoon
                                                
                                                
author). We cannot recommend this path today but do not
consider the way to be shut, especially given liberal use of
volatile.
</p><!--l. 456--><p class="indent" >   In particular, fused multiply-add operations are subject to
reordering by an optimizing compiler. Avoiding these would
require some discipline on the part of the jet developer, since
code that does not explicitly fma may yet reduce to it in a
compiler pass. A jetting library would be advantageous in this
case.
</p><!--l. 458--><p class="indent" >   As an example of a refactoring of <span 
class="ec-lmcsc-10">ieee </span>754 operations
for determinism, consider the ReproBLAS project (last
update ~2016.2.21). ReproBLAS seeks to produce a set
of reproducible deterministic algorithms reﬂecting the
standard operations of <span 
class="ec-lmcsc-10">blas </span>(<a  id="x1-25004"></a> Ahrens, Nguyen, and
Demmel, 2018). It accomplishes this by introducing a
binned data type and a set of basic operations carefully
built on <span 
class="ec-lmcsc-10">ieee </span>754 for the objective of completely portable
reproducibility.<span class="footnote-mark"><a href="#fn42x0"><sup class="textsuperscript">42</sup></a></span><a  id="x1-25005f42"></a> 
This is similar to our proposal for a vetted jetting library and
may be worth attention, particularly in association with
requirements around -O0.
</p>
<!--l. 460--><p class="noindent" ><span class="paragraphHead"><a  id="x1-26000"></a><span 
class="ec-lmbx-10">Proscribe by replacement.</span></span>
   Finally, we face the possibility of jettisoning decades of
ﬂoating-point libraries entirely and forging a new trail. We
explicitly omit attempting to implement a new standard as
hubristic, but would like to explore some alternatives.
</p>
<!--l. 464--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-27000"></a><span 
class="ec-lmbx-10">Posits.</span></span>
                                                
                                                
   In 2015, John Gustafson proposed a new standard for representing
values drawn from \(\mathbb {R}\) called universal numbers or unums (<a  id="x1-27001"></a> Gustafson,
2015).<span class="footnote-mark"><a href="#fn43x0"><sup class="textsuperscript">43</sup></a></span><a  id="x1-27002f43"></a> 
The current version supports interval arithmetic and greater
resolution near 1.0, at the cost of decreased resolution for
extremely large and extremely small values. Unums also
guarantee associativity and distributivity of operations.
</p><!--l. 468--><p class="indent" >   Gustafson’s criticisms of <span 
class="ec-lmcsc-10">ieee </span>754 focused on determinism
and exactness; underﬂow and overﬂow; ﬁxed bit widths for
mantissa and exponent; rounding; and the large wasted block
of NaNs (<a  id="x1-27006"></a> Risse, 2016). Unums likewise must provide sign,
exponent with bias, and signiﬁcand; they may additionally
signal whether the value is an interval. Unlike <span 
class="ec-lmcsc-10">ieee </span>754’s use
of multiple bit widths, 32-bit “posits” (ﬁxed-size unums
intended to facilitate hardware requirements) are argued to be
suﬃcient for almost all applications.
</p><!--l. 470--><p class="indent" >   The unum proposal appears to have settled somewhat after
its initial state of relative ﬂux (as Type <span 
class="ec-lmcsc-10">iii </span>unums, cf. <a  id="x1-27007"></a> Posit
Working Group (2022)). Although most implementations have
been in software, the project has been speciﬁed in Verilog
several times and implemented on <span 
class="ec-lmcsc-10">fpga</span>s (<a  id="x1-27008"></a> Chen, Al-Ars, and
Hofstee (2018), and VividSparks, <a href="https://vividsparks.tech/" class="url" >https://vividsparks<span 
class="cmmi-10">.</span>tech/</a>).
Intriguingly, some initial work has been carried out towards a
fundamental <span 
class="ec-lmcsc-10">blas</span>-like library built on posits (<a  id="x1-27009"></a> van Dam et al.,
2019).
</p><!--l. 472--><p class="indent" >   A unum/posit implementation for Urbit would be as
straightforward as its implementation of <span 
class="ec-lmcsc-10">ieee </span>754. For jetting,
there is a software library for posits available called SoftPosit
based on the SoftFloat library (<a  id="x1-27010"></a> Cerlane, 2018). (Until
commercial hardware implementations become available,
the eﬀect of optimizations on determinism cannot yet
be assessed; it is presumed that the situation will be
better than <span 
class="ec-lmcsc-10">ieee </span>754 given the advantages of a clean
slate.)
                                                
                                                
</p>
<!--l. 474--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-28000"></a><span 
class="ec-lmbx-10">Hand-rolled ﬂoats.</span></span>
   If <span 
class="ec-lmcsc-10">ieee </span>754 presents too many diﬃculties to be
viable at high speed, then hand-rolling a custom hybrid
hardware–software scheme via bitmasking could be attractive.
This returns to the more “Wild West” days before <span 
class="ec-lmcsc-10">ieee </span>754’s
introduction, but is presaged by the recent introduction
of bﬂoat16, TensorFlow-32, and other types designed
for machine learning applications. Without access to
hardware manufacturers, however, this amounts in the end to
software-deﬁned ﬂoating point and seems unlikely to
be competitive speedwise. (We cite the idea put forth
previously in this article to convert to an intermediate
representation for computation, yielding <span 
class="ec-lmcsc-10">ieee </span>754 as
necessary.)
</p><!--l. 478--><p class="indent" >   It may also be worth considering the use of a 3-tuple
of sign, exponent, and signiﬁcand (with only software
jetting), and leave details of jet implementation to library
authors. Hoon provides such a primitive in <code class="lstinline"><span style="color:#000000">++fn</span></code>, a tuple for
base-2 ﬂoating-point arithmetic supplying ﬁelds for sign, a
signed exponent without bias, and an arbitrary-precision
signiﬁcand.
</p>
<!--l. 480--><p class="indent" >   <span class="subparagraphHead"> <a  id="x1-29000"></a><span 
class="ec-lmbx-10">Fixed-point and</span> \(\mathbb {Q}\)<span 
class="ec-lmbx-10">.</span></span>
   A ﬁxed-point representation diﬀers from a ﬂoating-point
scheme in that the exponent is ﬁxed by the protocol or
metadata and thus only the sign and signiﬁcand need
be included in the bit representation. (With an oﬀset,
even the sign can be elided.) The advantage of such a
scheme is that it aﬀords the beneﬁts of ﬂoating-point
mathematics at near-integer operation speeds (e. g. left-shift
to multiply by two). One disadvantage is that there is
a smallest representable value; this lack of subnormals
requires either an underﬂow handler or the possibility
of inadvertent division by zero. Fixed-point operations
could also be used as intermediates in calculations.
                                                
                                                
(This echoes once again the idea of conversion to an
intermediate representation then conversion back out to <span 
class="ec-lmcsc-10">ieee</span>
754.)<span class="footnote-mark"><a href="#fn44x0"><sup class="textsuperscript">44</sup></a></span><a  id="x1-29001f44"></a> 
</p><!--l. 485--><p class="indent" >   If a rational number scheme is implemented, then a variety
of possible implementations are possible, ranging from
bitpacked ﬁxed-width integers to pairs of arbitrary-width
integers. Reduction to “simplest” values introduces some
overhead; fractions are formally an ordered pair \((a, b)\) with \(b \neq 0\),
but there is an equivalence class of multiples. (That is,
if we write \(\frac {1}{2}\) as \((1, 2)\), we have also to consider \((2, 4)\), \((3, 6)\), indeed an
inﬁnite sequence of such ordered pairs.) Rational numbers
are a superset of ﬂoating-point numbers and ﬁxed-point
numbers, but accrue processing overhead due to dereferencing
arbitrary integers and other aspects of computation on
operations.
</p><!--l. 487--><p class="indent" >   However, deviation from the proscription scheme, even
inadvertently, would mean that a ship is considered invalid in
a sense equivalent to double-booting or breaking the scry
namespace. This option is deemed worth investigation, likely
viable, but bearing unknown risks.
</p>
   <h4 class="subsectionHead"><span class="titlemark">4.6   </span> <a  id="x1-300004.6"></a>Irregularities</h4>
<!--l. 492--><p class="noindent" >Any approach to modeling real numbers runs the risk
that diﬀerent calculation pathways will yield a diﬀerent
kind of inexactness in the result. These can be mitigated
by some of the approaches suggested above, and also
by checking the correspondence of the Hoon code and
the underlying jet, particular for known edge cases in
behavior. While Hoon–jet compliance is an open research
                                                
                                                
problem,<span class="footnote-mark"><a href="#fn45x0"><sup class="textsuperscript">45</sup></a></span><a  id="x1-30001f45"></a> 
we can apply principles of unit testing
together with a period of testing Nock and jet
compliance.<span class="footnote-mark"><a href="#fn46x0"><sup class="textsuperscript">46</sup></a></span><a  id="x1-30002f46"></a> 
</p><!--l. 494--><p class="indent" >   Jet mismatches have been rare in the current
era.<span class="footnote-mark"><a href="#fn47x0"><sup class="textsuperscript">47</sup></a></span><a  id="x1-30003f47"></a> 
Some jet “mismatches” occur because the runtime raises a
diﬀerent error than the corresponding Hoon—these are
relatively innocuous. Others may occur because actually
diﬀerent results are produced for diﬀerent input. These are
grave, and ultimately motivated the introduction of the
epoch system so that event log replays can take into
account the previous less-perfect jet version in the runtime (<a  id="x1-30005"></a>
<code>~mastyr-bottec</code>, 2023).
</p>
   <h3 class="sectionHead"><span class="titlemark">5   </span> <a  id="x1-310005"></a>Linear Algebra in Hoon</h3>
<!--l. 498--><p class="noindent" >Lagoon<span class="footnote-mark"><a href="#fn48x0"><sup class="textsuperscript">48</sup></a></span><a  id="x1-31001f48"></a> 
is an Urbit library to facilitate Hoon-native mathematical
operations. It envisions six native types,
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-31003x1">
     <!--l. 501--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%real</span></code>, an <span 
class="ec-lmcsc-10">ieee </span>754 ﬂoating-point value
                                                
                                                
     </p></li>
<li 
  class="enumerate" id="x1-31005x2">
     <!--l. 502--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%uint</span></code>, an unsigned integer
     </p></li>
<li 
  class="enumerate" id="x1-31007x3">
     <!--l. 503--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%int2</span></code>, a twos-complement signed integer
     </p></li>
<li 
  class="enumerate" id="x1-31009x4">
     <!--l. 504--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%cplx</span></code>, a <span 
class="ec-lmcsc-10">blas</span>-compatible ordered pair
     </p></li>
<li 
  class="enumerate" id="x1-31011x5">
     <!--l. 505--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%unum</span></code>, a unum/posit value
     </p></li>
<li 
  class="enumerate" id="x1-31013x6">
     <!--l. 506--><p class="noindent" ><code class="lstinline"><span style="color:#000000">%fixp</span></code>, a ﬁxed-precision value</p></li></ol>
<!--l. 509--><p class="noindent" >for which <code class="lstinline"><span style="color:#000000">%real</span></code> allows the rounding mode to be speciﬁed;
<code class="lstinline"><span style="color:#000000">%cplx</span></code> consists of a pair of two values, real and imaginary
parts; and <code class="lstinline"><span style="color:#000000">%fixp</span></code> requires the expected precision.
</p><!--l. 512--><p class="indent" >   Lagoon implements algorithmically correct reference
implementation in Hoon with the expectation that
<code class="lstinline"><span style="color:#000000">/lib/lagoon</span></code> will be jetted. Operations include basic
arithmetic, vector and matrix row/column operations, matrix
multiplication, and matrix inversion. The jetting scheme may
take advantage of software libraries or appropriate hardware, but
must hew to the dictum that “if it’s not deterministic, it isn’t
                                                
                                                
real.”<span class="footnote-mark"><a href="#fn49x0"><sup class="textsuperscript">49</sup></a></span><a  id="x1-31014f49"></a> 
</p><!--l. 514--><p class="indent" >   Lagoon has passed through several implementations and
remains in active development. The current implementation is
the lagoon branch of the urbit/urbit repository (<a  id="x1-31017"></a> Urbit
Foundation, 2023).
</p>
   <h3 class="sectionHead"><span class="titlemark">6   </span> <a  id="x1-320006"></a>Conclusion</h3>
<!--l. 519--><p class="noindent" >To summarize, the most promising solutions for ﬂoating-point
mathematics on Urbit per the above analysis include:
</p><!--l. 521--><p class="indent" >
     </p><ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-32002x1">
     <!--l. 522--><p class="noindent" >Hardware ﬂoating point on single machine for entire
     lifetime.
     </p></li>
<li 
  class="enumerate" id="x1-32004x2">
     <!--l. 523--><p class="noindent" >Optimized software ﬂoating point with vetted jetting
     library.
     </p></li>
<li 
  class="enumerate" id="x1-32006x3">
     <!--l. 524--><p class="noindent" >Opaque calculation as callback.
                                                
                                                
     </p></li>
<li 
  class="enumerate" id="x1-32008x4">
     <!--l. 525--><p class="noindent" >Cached results by callsite.
     </p></li>
<li 
  class="enumerate" id="x1-32010x5">
     <!--l. 526--><p class="noindent" >Utilizing a subset of <span 
class="ec-lmcsc-10">ieee </span>754 in hardware.
     </p></li>
<li 
  class="enumerate" id="x1-32012x6">
     <!--l. 527--><p class="noindent" >Replacing  <span 
class="ec-lmcsc-10">ieee  </span>754  with  another  approach  of
     suﬃcient speed, ﬁxed-point and unum/posits chief
     among these.</p></li></ol>
<!--l. 530--><p class="indent" >   Several recent eﬀorts on Urbit have encountered
diﬃculties in producing reliably deterministic and
suﬃciently fast ﬂoating-point calculations on a Nock-based
system.<span class="footnote-mark"><a href="#fn50x0"><sup class="textsuperscript">50</sup></a></span><a  id="x1-32013f50"></a> 
We anticipate that, water ﬁnding its own level, each will adopt
a suitable deterministic solution for evaluation in Nock.
We do not anticipate these to be the last foundational
numerical libraries built on Urbit, but instead among the ﬁrst.
Thus we have documented the paths we have explored
as an annotated map for future travelers in search of
a one true representation for continuous mathematics.
 <img 
src="ustj-logo-.png" alt="PIC"  
width="337" height="337"  />
                                                
                                                
</p>
   <h3 class="sectionHead"><a  id="x1-33000"></a>References</h3>
<!--l. 534--><p class="noindent" >
   </p><dl class="thebibliography"><dt id="X0-KloudKoder2022" class="thebibliography">
</dt><dd 
id="bib-1" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@KloudKoder2022"></a>@KloudKoder
   (2022)
   “Floating-point
   rounding
   mode
   control
   prototyping
   (WebAssembly
   Issue
   #1456)”.
   <span class="small-caps">url</span>:
   <a href="https://github.com/WebAssembly/design/issues/1456" class="url" >https://github.com/WebAssembly/design/issues/1456</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-ReproBLAS" class="thebibliography">
</dt><dd 
id="bib-2" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@ReproBLAS"></a>Ahrens, Peter,
   Hong Diep Nguyen,
   and
   James Demmel
   (2018)
   “ReproBLAS:
   Reproducible
   Basic
   Linear
   Algebra
   Subprograms”.
   <span class="small-caps">url</span>:
                                                
                                                
   <a href="https://bebop.cs.berkeley.edu/reproblas" class="url" >https://bebop.cs.berkeley.edu/reproblas</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Andrysco2016" class="thebibliography">
</dt><dd 
id="bib-3" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Andrysco2016"></a>Andryso, Marc,
   Ranjit Jhala,
   and
   Sorin Lerner
   (2016).
   “Printing
   Floating-Point
   Numbers:
   A
   Faster,
   Always
   Correct
   Method.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span 
class="ec-lmri-10">43rd</span>
   <span 
class="ec-lmri-10">Annual</span>
   <span class="small-caps">acm</span>
   <span class="small-caps">sigplan-sigact</span>
   <span 
class="ec-lmri-10">Symposium</span>
   <span 
class="ec-lmri-10">on</span>
   <span 
class="ec-lmri-10">Principles</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Programming</span>
   <span 
class="ec-lmri-10">Languages</span>
   <span 
class="ec-lmri-10">(</span><span class="small-caps">popl</span>
   <span 
class="ec-lmri-10">’16)</span>,
   pp. 555–567.
   <span class="small-caps">doi</span>:
   <a href="https://doi.org/10.1145/2837614.2837654" >10.1145/2837614.2837654</a>.
                                                
                                                
   <span class="small-caps">url</span>:
   <a href="https://dl.acm.org/doi/10.1145/2837614.2837654" class="url" >https://dl.acm.org/doi/10.1145/2837614.2837654</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Apple1994" class="thebibliography">
</dt><dd 
id="bib-4" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Apple1994"></a>Apple Computer, Inc.
   (1994).
   <span 
class="ec-lmri-10">Inside</span>
   <span 
class="ec-lmri-10">Macintosh:</span>
   <span 
class="ec-lmri-10">PowerPC</span>
   <span 
class="ec-lmri-10">System</span>
   <span 
class="ec-lmri-10">Software</span>.
   Boston:
   Addison-Wesley.
   <span class="small-caps">url</span>:
   <a href="https://developer.apple.com/library/archive/documentation/mac/pdf/PPC_System_Software/Intro_to_PowerPC.pdf" class="url" >https://developer.apple.com/library/archive/documentation/mac/pdf/PPC_System_Software/Intro_to_PowerPC.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Babuska1969" class="thebibliography">
</dt><dd 
id="bib-5" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Babuska1969"></a>Babuška, Ivo
   (1969).
   “Numerical
   stability
   in
   mathematical
   analysis.”
   In:
   <span 
class="ec-lmri-10">Information</span>
   <span 
class="ec-lmri-10">Processing</span>
   68,
   pp. 11–23.
                                                
                                                
   </p></dd><dt id="X0-LeBrun2018" class="thebibliography">
</dt><dd 
id="bib-6" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@LeBrun2018"></a>Brun, Laurent Le
   (2018)
   “Making
   ﬂoating
   point
   numbers
   smaller”.
   <span class="small-caps">url</span>:
   <a href="https://www.ctrl-alt-test.fr/2018/making-floating-point-numbers-smaller/" class="url" >https://www.ctrl-alt-test.fr/2018/making-ﬂoating-point-numbers-smaller/</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-CPPRef" class="thebibliography">
</dt><dd 
id="bib-7" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@CPPRef"></a>C++
   Reference
   (2023)
   “Floating-point
   environment”.
   <span class="small-caps">url</span>:
   <a href="https://en.cppreference.com/w/c/numeric/fenv" class="url" >https://en.cppreference.com/w/c/numeric/fenv</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Cerlane2018" class="thebibliography">
</dt><dd 
id="bib-8" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Cerlane2018"></a>Cerlane, Leong
   (2018)
   “SoftPosit”.
   <span class="small-caps">url</span>:
   <a href="https://gitlab.com/cerlane/SoftPosit" class="url" >https://gitlab.com/cerlane/SoftPosit</a>
   (visited
   on
   ~2024.3.10).
                                                
                                                
   </p></dd><dt id="X0-Chen2018" class="thebibliography">
</dt><dd 
id="bib-9" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Chen2018"></a>Chen, Jianyu,
   Zaid Al-Ars,
   and
   H. Peter Hofstee
   (2018).
   “A
   matrix-multiply
   unit
   for
   posits
   in
   reconﬁgurable
   logic
   leveraging
   (open)
   <span 
class="ec-lmcsc-10">capi</span>.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span 
class="ec-lmri-10">Conference</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Next</span>
   <span 
class="ec-lmri-10">Generation</span>
   <span 
class="ec-lmri-10">Arithmetic</span>,
   pp. 1–5.
   </p></dd><dt id="X0-Chohra2016" class="thebibliography">
</dt><dd 
id="bib-10" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Chohra2016"></a>Chohra, Chemseddine,
   Philippe Langlois,
   and
   David Parello
   (2016).
   “Eﬃciency
   of
                                                
                                                
   Reproducible
   Level
   1
   <span 
class="ec-lmcsc-10">blas</span>.”
   In:
   <span 
class="ec-lmri-10">Scientiﬁc</span>
   <span 
class="ec-lmri-10">Computing,</span>
   <span 
class="ec-lmri-10">Computer</span>
   <span 
class="ec-lmri-10">Arithmetic,</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Validated</span>
   <span 
class="ec-lmri-10">Numerics</span>.
   Ed. by
   Marco Nehmeier,
   Jürgen Wolﬀ
   von
   Gudenberg,
   and
   Warwick Tucker.
   Berlin:
   Springer
   International
   Publishing,
   pp. 99–108.
   </p></dd><dt id="X0-Citron1998" class="thebibliography">
</dt><dd 
id="bib-11" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Citron1998"></a>Citron, D.,
   D. Feitelson,
   and
   L. Rudolph
   (1998).
   “Accelerating
   multi-media
   processing
   by
   implementing
   memoing
   in
                                                
                                                
   multiplication
   and
   division
   units.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">8th</span>
   <span 
class="ec-lmri-10">International</span>
   <span 
class="ec-lmri-10">Conference</span>
   <span 
class="ec-lmri-10">on</span>
   <span 
class="ec-lmri-10">Architectural</span>
   <span 
class="ec-lmri-10">Support</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Programming</span>
   <span 
class="ec-lmri-10">Languages</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Operating</span>
   <span 
class="ec-lmri-10">Systems</span>
   <span 
class="ec-lmri-10">(</span><span class="small-caps">asplos-viii</span><span 
class="ec-lmri-10">)</span>,
   pp. 252–261.
   </p></dd><dt id="X0-Dawson2013" class="thebibliography">
</dt><dd 
id="bib-12" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Dawson2013"></a>Dawson, Bruce
   (2013)
   “Floating-Point
   Determinism”.
   Random
   <span class="small-caps">ascii</span>
   –
   tech
   blog
   of
   Bruce
   Dawson.
   <span class="small-caps">url</span>:
   <a href="https://randomascii.wordpress.com/2013/07/16/floating-point-determinism/" class="url" >https://randomascii.wordpress.com/2013/07/16/ﬂoating-point-determinism/</a>
   (visited
                                                
                                                
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Demmel2017" class="thebibliography">
</dt><dd 
id="bib-13" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Demmel2017"></a>Demmel, James
   et al.
   (2017)
   “A
   Proposal
   for
   a
   Next-Generation
   <span 
class="ec-lmcsc-10">blas</span>”.
   <span class="small-caps">url</span>:
   <a href="https://docs.google.com/document/d/1DY4ImZT1coqri2382GusXgBTTTVdBDvtD5I14QHp9OE/edit#heading=h.jtgipeoidy9" class="url" >https://docs.google.com/document/d/1DY4ImZT1coqri2382GusXgBTTTVdBDvtD5I14QHp9OE/edit#heading=h.jtgipeoidy9</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-UrWasm" class="thebibliography">
</dt><dd 
id="bib-14" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@UrWasm"></a><code>~dozreg-toplud</code>, K. Afonin
   (2023)
   “UrWasm”.
   <span class="small-caps">url</span>:
   <a href="https://github.com/Quodss/urwasm" class="url" >https://github.com/Quodss/urwasm</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Afonin2024" class="thebibliography">
</dt><dd 
id="bib-15" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Afonin2024"></a>—   (2024).
   “The
   urwasm
   WebAssembly
   Interpreter
   Suite
                                                
                                                
   on
   Urbit.”
   In:
   <span 
class="ec-lmri-10">Urbit</span>
   <span 
class="ec-lmri-10">Systems</span>
   <span 
class="ec-lmri-10">Technical</span>
   <span 
class="ec-lmri-10">Journal</span>
   1.1,
   pp. 133–150.
   </p></dd><dt id="X0-Edelman1997" class="thebibliography">
</dt><dd 
id="bib-16" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Edelman1997"></a>Edelman, Alan
   (1997).
   “The
   Mathematics
   of
   the
   Pentium
   Division
   Bug.”
   In:
   <span class="small-caps">siam</span>
   <span 
class="ec-lmri-10">Review</span>
   39.1,
   pp. 54–67.
   <span class="small-caps">doi</span>:
   <a href="https://doi.org/10.1137/S0036144595293959" >10.1137/S0036144595293959</a>.
   </p></dd><dt id="X0-Figueroa2000" class="thebibliography">
</dt><dd 
id="bib-17" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Figueroa2000"></a>Figueroa
   del
   Cid, S. A.
   (2000).
   “A
   Rigorous
   Framework
   for
                                                
                                                
   Fully
   Supporting
   the
   <span 
class="ec-lmcsc-10">ieee</span>
   Standard
   for
   Floating-Point
   Arithmetic
   in
   High-Level
   Programming
   Languages.”
   PhD thesis.
   New
   York
   University.
   </p></dd><dt id="X0-Foote1999" class="thebibliography">
</dt><dd 
id="bib-18" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Foote1999"></a>Foote, Brian
   and
   Joseph Yoder
   (1999)
   “Big
   Ball
   of
   Mud”.
   <span class="small-caps">url</span>:
   <a href="http://laputan.org/mud/mud.html" class="url" >http://laputan.org/mud/mud.html</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-GCCWiki" class="thebibliography">
</dt><dd 
id="bib-19" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@GCCWiki"></a><span 
class="ec-lmcsc-10">gnu</span>
   Project
   (2008)
   “Software
                                                
                                                
   Floating
   Point”.
   <span class="small-caps">url</span>:
   <a href="https://gcc.gnu.org/wiki/Software_floating_point" class="url" >https://gcc.gnu.org/wiki/Software_ﬂoating_point</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Goldberg1991" class="thebibliography">
</dt><dd 
id="bib-20" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Goldberg1991"></a>Goldberg, David
   (1991).
   “What
   Every
   Computer
   Scientist
   Should
   Know
   About
   Floating-Point
   Arithmetic.”
   In:
   <span class="small-caps">acm</span>
   <span 
class="ec-lmri-10">Computing</span>
   <span 
class="ec-lmri-10">Surveys</span>
   23.1,
   pp. 5–48.
   <span class="small-caps">url</span>:
   <a href="https://dl.acm.org/doi/pdf/10.1145/103162.103163" class="url" >https://dl.acm.org/doi/pdf/10.1145/103162.103163</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Gustafson2015" class="thebibliography">
</dt><dd 
id="bib-21" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Gustafson2015"></a>Gustafson, John L.
   (2015).
   <span 
class="ec-lmri-10">The</span>
   <span 
class="ec-lmri-10">End</span>
                                                
                                                
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Error:</span>
   <span 
class="ec-lmri-10">Unum</span>
   <span 
class="ec-lmri-10">Computing</span>.
   A.
   K.
   Peters/<span 
class="ec-lmcsc-10">crc</span>
   Press.
   <span class="small-caps">isbn</span>:
   978-1-4822-3986-7.
   </p></dd><dt id="X0-Gustafson2017a" class="thebibliography">
</dt><dd 
id="bib-22" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Gustafson2017a"></a>—   (2017a)
   “Beyond
   Floating
   Point:
   Next
   Generation
   Computer
   Arithmetic
   (Stanford
   Seminar)”.
   <span class="small-caps">url</span>:
   <a href="https://www.youtube.com/watch?v=aP0Y1uAA-2Y" class="url" >https://www.youtube.com/watch?v=aP0Y1uAA-2Y</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Gustafson2017" class="thebibliography">
</dt><dd 
id="bib-23" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Gustafson2017"></a>—   (2017b)
   “Posit
   Arithmetic”.
   <span class="small-caps">url</span>:
   <a href="https://posithub.org/docs/Posits4.pdf" class="url" >https://posithub.org/docs/Posits4.pdf</a>
   (visited
   on
   ~2024.3.10).
                                                
                                                
   </p></dd><dt id="X0-Gustafson2017b" class="thebibliography">
</dt><dd 
id="bib-24" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Gustafson2017b"></a>Gustafson, John L.
   and
   Isaac Yonemoto
   (2017).
   “Beating
   Floating
   Point
   at
   its
   Own
   Game:
   Posit
   Arithmetic.”
   In:
   <span 
class="ec-lmri-10">Journal</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Supercomputing</span>
   <span 
class="ec-lmri-10">Frontiers</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Innovations</span>
   4.2,
   pp. 71–86.
   <span class="small-caps">doi</span>:
   <a href="https://doi.org/10.14529/jsfi170206" >10.14529/jsﬁ170206</a>.
   </p></dd><dt id="X0-Hauser2018" class="thebibliography">
</dt><dd 
id="bib-25" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Hauser2018"></a>Hauser, John R.
   (2018)
   “Berkeley
   SoftFloat
   Release
   3e”.
   <span class="small-caps">url</span>:
   <a href="http://www.jhauser.us/arithmetic/SoftFloat-3/doc/SoftFloat.html" class="url" >http://www.jhauser.us/arithmetic/SoftFloat-3/doc/SoftFloat.html</a>
   (visited
                                                
                                                
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Higham2002" class="thebibliography">
</dt><dd 
id="bib-26" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Higham2002"></a>Higham, Nicholas J.
   (2002).
   <span 
class="ec-lmri-10">Accuracy</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Stability</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Numerical</span>
   <span 
class="ec-lmri-10">Algorithms</span>.
   2nd
   ed.
   Philadelphia:
   <span 
class="ec-lmcsc-10">siam</span>.
   </p></dd><dt id="X0-SEPPythagoras" class="thebibliography">
</dt><dd 
id="bib-27" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@SEPPythagoras"></a>Huﬀman, Carl
   (2024).
   “Pythagoras.”
   In:
   <span 
class="ec-lmri-10">The</span>
   <span 
class="ec-lmri-10">Stanford</span>
   <span 
class="ec-lmri-10">Encyclopedia</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Philosophy</span>.
   Ed. by
   Edward N. Zalta
   and
   Uri Nodelman.
   Spring
   2024.
   Metaphysics
   Research
   Lab,
                                                
                                                
   Stanford
   University.
   </p></dd><dt id="X0-IEEE754-2008" class="thebibliography">
</dt><dd 
id="bib-28" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@IEEE754-2008"></a><span 
class="ec-lmcsc-10">ieee</span>
   (2008).
   <span 
class="ec-lmri-10">754-2008</span>
   <span 
class="ec-lmcsc-10">ieee</span>
   <span 
class="ec-lmri-10">Standard</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Floating-Point</span>
   <span 
class="ec-lmri-10">Arithmetic</span>.
   Tech. rep.
   Institute
   of
   Electrical
   and
   Electronics
   Engineers.
   <span class="small-caps">url</span>:
   <a href="https://ieeexplore.ieee.org/document/4610935" class="url" >https://ieeexplore.ieee.org/document/4610935</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-ISO9899" class="thebibliography">
</dt><dd 
id="bib-29" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@ISO9899"></a><span 
class="ec-lmcsc-10">iso</span>/<span 
class="ec-lmcsc-10">iec</span>
   (2018).
   <span class="small-caps">iso</span><span 
class="ec-lmri-10">/</span><span class="small-caps">iec</span>
   <span 
class="ec-lmri-10">9899:2018</span>
   <span 
class="ec-lmri-10">Information</span>
   <span 
class="ec-lmri-10">technology</span>
   <span 
class="ec-lmri-10">–</span>
   <span 
class="ec-lmri-10">Programming</span>
   <span 
class="ec-lmri-10">languages</span>
   <span 
class="ec-lmri-10">–</span>
   <span 
class="ec-lmri-10">C</span>.
                                                
                                                
   Tech. rep.
   International
   Organization
   for
   Standardization.
   <span class="small-caps">url</span>:
   <a href="https://www.iso.org/standard/74528.html" class="url" >https://www.iso.org/standard/74528.html</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Izquierdo2006" class="thebibliography">
</dt><dd 
id="bib-30" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Izquierdo2006"></a>Izquierdo, Luis R.
   and
   J. Gary Polhill
   (2006).
   “Is
   your
   model
   susceptible
   to
   ﬂoating
   point
   errors?”
   In:
   <span 
class="ec-lmri-10">Journal</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Artiﬁcial</span>
   <span 
class="ec-lmri-10">Societies</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Social</span>
   <span 
class="ec-lmri-10">Simulation</span>
   9.4.
   <span class="small-caps">url</span>:
   <a href="https://www.jasss.org/9/4/4.html" class="url" >https://www.jasss.org/9/4/4.html</a>
   (visited
   on
   ~2024.3.10).
                                                
                                                
   </p></dd><dt id="X0-Jones2008" class="thebibliography">
</dt><dd 
id="bib-31" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Jones2008"></a>Jones, Derek M.
   (2008).
   <span 
class="ec-lmri-10">The</span>
   <span 
class="ec-lmri-10">New</span>
   <span 
class="ec-lmri-10">C</span>
   <span 
class="ec-lmri-10">Standard:</span>
   <span 
class="ec-lmri-10">An</span>
   <span 
class="ec-lmri-10">Economic</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Cultural</span>
   <span 
class="ec-lmri-10">Commentary</span>.
   <span class="small-caps">url</span>:
   <a href="http://www.knosof.co.uk/cbook/cbook.html" class="url" >http://www.knosof.co.uk/cbook/cbook.html</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Kahan1965" class="thebibliography">
</dt><dd 
id="bib-32" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Kahan1965"></a>Kahan, William
   (1965).
   “Further
   remarks
   on
   reducing
   truncation
   errors.”
   In:
   <span 
class="ec-lmri-10">Communications</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span class="small-caps">acm</span>
   8.1,
   p. 40.
   <span class="small-caps">doi</span>:
   <a href="https://doi.org/10.1145/363707.363723" >10.1145/363707.363723</a>.
                                                
                                                
   </p></dd><dt id="X0-Kahan1997" class="thebibliography">
</dt><dd 
id="bib-33" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Kahan1997"></a>—   (1997a)
   “Lecture
   Notes
   on
   the
   Status
   of
   <span 
class="ec-lmcsc-10">ieee</span>
   Standard
   754
   for
   Binary
   Floating-Point
   Arithmetic”.
   <span class="small-caps">url</span>:
   <a href="https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF" class="url" >https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Kahan1997a" class="thebibliography">
</dt><dd 
id="bib-34" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Kahan1997a"></a>—   (1997b)
   “The
   Baleful
   Eﬀect
   of
   Computer
   Languages
   and
   Benchmarks
   upon
   Applied
   Mathematics,
   Physics
   and
                                                
                                                
   Chemistry
   (John
   von
   Neumann
   Lecture)”.
   <span class="small-caps">url</span>:
   <a href="https://people.eecs.berkeley.edu/~wkahan/SIAMjvnl.pdf" class="url" >https://people.eecs.berkeley.edu/~wkahan/SIAMjvnl.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Kharva2020" class="thebibliography">
</dt><dd 
id="bib-35" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Kharva2020"></a>Kharva, Paresh
   (2020)
   “TensorFloat-32
   in
   the
   A100
   <span 
class="ec-lmcsc-10">gpu</span>
   Accelerates
   AI
   Training,
   <span 
class="ec-lmcsc-10">hpc</span>
   up
   to
   20×”.
   <span class="small-caps">url</span>:
   <a href="https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/" class="url" >https://blogs.nvidia.com/blog/2020/05/14/tensorﬂoat-32-precision-format/</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Koenig2018" class="thebibliography">
</dt><dd 
id="bib-36" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Koenig2018"></a>Koenig, Jack
   (2018).
   <span 
class="ec-lmri-10">A</span>
   <span 
class="ec-lmri-10">Hardware</span>
                                                
                                                
   <span 
class="ec-lmri-10">Accelerator</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Computing</span>
   <span 
class="ec-lmri-10">an</span>
   <span 
class="ec-lmri-10">Exact</span>
   <span 
class="ec-lmri-10">Dot</span>
   <span 
class="ec-lmri-10">Product</span>.
   Tech. rep.
   <span class="small-caps">ucb</span>/<span class="small-caps">eecs</span>-2018-51.
   University
   of
   California,
   Berkeley.
   <span class="small-caps">url</span>:
   <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-51.pdf" class="url" >https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-51.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-MacDonald1991" class="thebibliography">
</dt><dd 
id="bib-37" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@MacDonald1991"></a>MacDonald, Tom
   (1991).
   “C
   for
   Numerical
   Computing.”
   In:
   <span 
class="ec-lmri-10">Journal</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">Supercomputing</span>
   5.1,
   pp. 31–48.
   <span class="small-caps">doi</span>:
   <a href="https://doi.org/10.1007/BF00155856" >10.1007/BF00155856</a>.
   </p></dd><dt id="X0-UrbitEpoch" class="thebibliography">
</dt><dd 
id="bib-38" class="thebibliography">
                                                
                                                
   <!--l. 534--><p class="noindent" ><a  id="cite.0@UrbitEpoch"></a><code>~mastyr-bottec</code>, Matthew Levan
   (2023)
   “Epoch
   System”.
   <span class="small-caps">url</span>:
   <a href="https://roadmap.urbit.org/project/epoch-system" class="url" >https://roadmap.urbit.org/project/epoch-system</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Peters2021" class="thebibliography">
</dt><dd 
id="bib-39" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Peters2021"></a>Peters, Christoph
   (2021).
   “<span 
class="ec-lmcsc-10">fma</span>:
   A
   faster,
   more
   accurate
   instruction.”
   In:
   <span 
class="ec-lmri-10">Moments</span>
   <span 
class="ec-lmri-10">in</span>
   <span 
class="ec-lmri-10">Graphics</span>.
   <span class="small-caps">url</span>:
   <a href="https://momentsingraphics.de/FMA.html" class="url" >https://momentsingraphics.de/FMA.html</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Posit2022" class="thebibliography">
</dt><dd 
id="bib-40" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Posit2022"></a>Posit
   Working
   Group
   (2022).
   <span 
class="ec-lmri-10">Standard</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Posit</span><span 
class="ec-lmri-10">™</span>
                                                
                                                
   <span 
class="ec-lmri-10">Arithmetic</span>.
   Tech. rep.
   Posit
   Working
   Group.
   <span class="small-caps">url</span>:
   <a href="https://posithub.org/docs/posit_standard-2.pdf" class="url" >https://posithub.org/docs/posit_standard-2.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Risse2016" class="thebibliography">
</dt><dd 
id="bib-41" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Risse2016"></a>Risse, Thomas
   (2016).
   “It’s
   Time
   for
   Unums—an
   Alternative
   to
   <span 
class="ec-lmcsc-10">ieee</span>
   754
   Floats
   and
   Doubles.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span 
class="ec-lmri-10">Fifth</span>
   <span 
class="ec-lmri-10">International</span>
   <span 
class="ec-lmri-10">Conference</span>
   <span 
class="ec-lmri-10">on</span>
   <span 
class="ec-lmri-10">Signal</span>
   <span 
class="ec-lmri-10">&#x0026;</span>
   <span 
class="ec-lmri-10">Image</span>
   <span 
class="ec-lmri-10">Processing</span>
                                                
                                                
   <span 
class="ec-lmri-10">(</span><span class="small-caps">sip</span><span 
class="ec-lmri-10">-2016)</span>,
   pp. 50–51.
   </p></dd><dt id="X0-Sidwell2006" class="thebibliography">
</dt><dd 
id="bib-42" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Sidwell2006"></a>Sidwell, Nathan
   and
   Joseph Myers
   (2006).
   <span 
class="ec-lmri-10">Improving</span>
   <span 
class="ec-lmri-10">Software</span>
   <span 
class="ec-lmri-10">Floating</span>
   <span 
class="ec-lmri-10">Point</span>
   <span 
class="ec-lmri-10">Support</span>.
   Tech. rep.
   CodeSourcery.
   <span class="small-caps">url</span>:
   <a href="https://hashingit.com/elements/research-resources/2006-01-improving_software_floating_point_support.pdf" class="url" >https://hashingit.com/elements/research-resources/2006-01-improving_software_ﬂoating_point_support.pdf</a>
   (visited
   on
   ~2023.3.9).
   </p></dd><dt id="X0-Steele1991" class="thebibliography">
</dt><dd 
id="bib-43" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Steele1991"></a>Steele Jr., Guy L.
   and
   Jon L. White
   (1991).
   “How
   to
   print
   ﬂoating-point
   numbers
   accurately.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span 
class="ec-lmri-10">1990</span>
                                                
                                                
   <span class="small-caps">acm</span>
   <span class="small-caps">sigplan</span>
   <span 
class="ec-lmri-10">Conference</span>
   <span 
class="ec-lmri-10">on</span>
   <span 
class="ec-lmri-10">Programming</span>
   <span 
class="ec-lmri-10">Language</span>
   <span 
class="ec-lmri-10">Design</span>
   <span 
class="ec-lmri-10">and</span>
   <span 
class="ec-lmri-10">Implementation</span>
   <span 
class="ec-lmri-10">(</span><span class="small-caps">pldi</span>
   <span 
class="ec-lmri-10">’90)</span>,
   pp. 372–389.
   <span class="small-caps">url</span>:
   <a href="http://kurtstephens.com/files/p372-steele.pdf" class="url" >http://kurtstephens.com/ﬁles/p372-steele.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Thall2007" class="thebibliography">
</dt><dd 
id="bib-44" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Thall2007"></a>Thall, Andrew
   (2007).
   <span 
class="ec-lmri-10">Extended-Precision</span>
   <span 
class="ec-lmri-10">Floating-Point</span>
   <span 
class="ec-lmri-10">Numbers</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmcsc-10">gpu</span>
   <span 
class="ec-lmri-10">Computation</span>.
   Tech. rep.
   <span 
class="ec-lmcsc-10">cim</span>-007-01.
   The
   University
   of
   North
   Carolina
   at
   Chapel
   Hill.
   <span class="small-caps">url</span>:
                                                
                                                
   <a href="http://andrewthall.org/papers/df64_qf128.pdf" class="url" >http://andrewthall.org/papers/df64_qf128.pdf</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-UrbitBreach" class="thebibliography">
</dt><dd 
id="bib-45" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@UrbitBreach"></a>Tlon
   Corporation
   (2020)
   “The
   Last
   Network
   Breach”.
   <span class="small-caps">url</span>:
   <a href="https://roadmap.urbit.org/project/last-network-breach" class="url" >https://roadmap.urbit.org/project/last-network-breach</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Urbit" class="thebibliography">
</dt><dd 
id="bib-46" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Urbit"></a>Urbit
   Foundation
   (2023)
   “Urbit”.
   <span class="small-caps">url</span>:
   <a href="https://github.com/urbit/urbit" class="url" >https://github.com/urbit/urbit</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-vanDam2019" class="thebibliography">
</dt><dd 
id="bib-47" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@vanDam2019"></a>van
   Dam, Laurens
   et al.
   (2019).
   “An
                                                
                                                
   Accelerator
   for
   Posit
   Arithmetic
   Targeting
   Posit
   Level
   1
   <span 
class="ec-lmcsc-10">blas</span>
   Routines
   and
   Pair-<span 
class="ec-lmcsc-10">hmm</span>.”
   In:
   <span 
class="ec-lmri-10">Proceedings</span>
   <span 
class="ec-lmri-10">of</span>
   <span 
class="ec-lmri-10">the</span>
   <span 
class="ec-lmri-10">Conference</span>
   <span 
class="ec-lmri-10">for</span>
   <span 
class="ec-lmri-10">Next</span>
   <span 
class="ec-lmri-10">Generation</span>
   <span 
class="ec-lmri-10">Arithmetic</span>,
   pp. 1–10.
   </p></dd><dt id="X0-Wang2019" class="thebibliography">
</dt><dd 
id="bib-48" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Wang2019"></a>Wang, Shibo
   and
   Pankaj Kanwar
   (2019)
   “BFloat16:
   The
   secret
   to
   high
   performance
   on
   Cloud
   <span 
class="ec-lmcsc-10">tpu</span>s”.
   <span class="small-caps">url</span>:
                                                
                                                
   <a href="https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus" class="url" >https://cloud.google.com/blog/products/ai-machine-learning/bﬂoat16-the-secret-to-high-performance-on-cloud-tpus</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Monk2020" class="thebibliography">
</dt><dd 
id="bib-49" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Monk2020"></a><code>~wicdev-wisryt</code>, Philip C. Monk
   (2020a)
   “Urbit
   Precepts”.
   <span class="small-caps">url</span>:
   <a href="https://urbit.org/blog/precepts" class="url" >https://urbit.org/blog/precepts</a>
   (visited
   on
   ~2024.3.10).
   </p></dd><dt id="X0-Monk2020a" class="thebibliography">
</dt><dd 
id="bib-50" class="thebibliography">
   <!--l. 534--><p class="noindent" ><a  id="cite.0@Monk2020a"></a>—   (2020b)
   “Urbit
   Precepts
   (Discussion)”.
   <span class="small-caps">url</span>:
   <a href="https://urbit.org/blog/precepts-discussion" class="url" >https://urbit.org/blog/precepts-discussion</a>
   (visited
   on
   ~2024.3.10).</p></dd></dl>
    
<h3 class="sectionHead"><a id="x1-65536"></a>Footnotes</h3><p class="noindent" >
      <div class="footnote-text">
  <!--l. 50--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn1x0">   <sup class="textsuperscript">1</sup></a></span><span 
class="ec-lmr-8">Analog computers may operate on a continuum of value.</span>
  <span 
class="ec-lmr-8">Computer logic systems may be architected on other numeric bases for</span>
  <span 
class="ec-lmr-8">their logic, such as the 1837 Analytical Engine’s decimal system and the</span>
  <span 
class="ec-lmr-8">1958 Setun’s () ternary system.</span><a href="#x1-2002f1">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 53--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn2x0">   <sup class="textsuperscript">2</sup></a></span><span 
class="ec-lmr-8">This is reﬂected in algorithms such as the </span><span 
class="ec-lmr-8">“fast inverse square</span>
  <span 
class="ec-lmr-8">root</span><span 
class="ec-lmr-8">”, which permits a degree of inaccuracy in exchange for a substantial</span>
  <span 
class="ec-lmr-8">speedup.</span><a href="#x1-2003f2">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 53--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn3x0">   <sup class="textsuperscript">3</sup></a></span><span 
class="ec-lmr-8">To be clear, 3D gaming algorithms are deterministic (assuming</span>
  <span 
class="ec-lmr-8">no random sources are used), but exact error values are often not</span>
  <span 
class="ec-lmr-8">reproducible across platforms, nor was such portability a design criterion.</span>
  <span 
class="ec-lmr-8">The reasons for this are discussed below.</span><a href="#x1-2004f3">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 62--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn4x0">   <sup class="textsuperscript">4</sup></a></span><span 
class="ec-lmr-8">A legendary attribution, alas, predicated on the Pythagorean</span>
  <span 
class="ec-lmr-8">discovery of the irrational numbers as a separate class thereby inducing a</span>
  <span 
class="ec-lmr-8">crisis (</span><a 
 id="x5-3002"></a> <span 
class="ec-lmr-8">Huﬀman, 2024).</span><a href="#x1-3001f4">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 65--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn5x0">   <sup class="textsuperscript">5</sup></a></span><span 
class="ec-lmr-8">Hand-in-hand with the development of linear algebra,</span>
  <span 
class="ec-lmr-8">machines such as </span><span 
class="ec-lmcsc-10x-x-80">eniac </span><span 
class="ec-lmr-8">and </span><span 
class="ec-lmcsc-10x-x-80">maniac </span><span 
class="ec-lmr-8">were employed in the 1940s for</span>
  <span 
class="ec-lmr-8">solving thermonuclear reaction calculations and neutron diﬀusion</span>
  <span 
class="ec-lmr-8">equations. Under the direction of John von Neumann, it appears</span>
  <span 
class="ec-lmr-8">that some calculations did experimentally involve a ﬂoating-point</span>
  <span 
class="ec-lmr-8">scheme, although this was later rejected deﬁnitively in favor of</span>
  <span 
class="ec-lmr-8">ﬁxed-point arithmetic. See </span><a 
 id="x6-3004"></a> <span 
class="ec-lmr-8">Kahan (1997), p.</span><span 
class="ec-lmr-8"> 3, on ﬂoating-point</span>
  <span 
class="ec-lmr-8">representations.</span><a href="#x1-3003f5">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 67--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn6x0">   <sup class="textsuperscript">6</sup></a></span><span 
class="ec-lmr-8">Compare so-called </span><span 
class="ec-lmr-8">“engineering</span><span 
class="ec-lmr-8">” notation, such as 1e5 for 10,000,</span>
  <span 
class="ec-lmr-8">which compactly represents the signiﬁcand 1 and the exponent 5 with</span>
  <span 
class="ec-lmr-8">an understood base of 10 indicated by e and a sign, implicit for</span>
  <span 
class="ec-lmr-8">positive.</span><a href="#x1-3005f6">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 67--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn7x0">   <sup class="textsuperscript">7</sup></a></span><span 
class="ec-lmr-8">We cite bﬂoat16 (</span><a 
 id="x8-3007"></a> <span 
class="ec-lmr-8">Wang and Kanwar, 2019) and TensorFloat-32 (</span><a 
 id="x8-3008"></a>
  <span 
class="ec-lmr-8">Kharva, 2020), among others.</span><a href="#x1-3006f7">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 69--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn8x0">   <sup class="textsuperscript">8</sup></a></span><span 
class="ec-lmr-8">We could omit the sign by introducing an oﬀset or only allowing</span>
  <span 
class="ec-lmr-8">positive values.</span><a href="#x1-3009f8">⤴</a></p></div>
      


      <div class="footnote-text">
  <!--l. 69--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn9x0">   <sup class="textsuperscript">9</sup></a></span><span 
class="ec-lmr-8">The exponent has a bias so that it in turn does not need a</span>
  <span 
class="ec-lmr-8">sign.</span><a href="#x1-3010f9">⤴</a></p></div>
      


        <div class="footnote-text">
   <!--l. 74--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn10x0">  <sup class="textsuperscript">10</sup></a></span><span 
class="ec-lmr-8">We ignore the decimal representations introduced in </span><span 
class="ec-lmcsc-10x-x-80">ieee</span>
   <span 
class="ec-lmr-8">754-2008, which do not materially change our argument.</span><a href="#x1-4001f10">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 86--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn11x0">  <sup class="textsuperscript">11</sup></a></span><span 
class="ec-lmr-8">“Each of the computational operations that return a numeric</span>
   <span 
class="ec-lmr-8">result speciﬁed by this standard shall be performed as if it ﬁrst produced</span>
   <span 
class="ec-lmr-8">an intermediate result correct to inﬁnite precision and with unbounded</span>
   <span 
class="ec-lmr-8">range, and then rounded that intermediate result, if necessary, to ﬁt in</span>
   <span 
class="ec-lmr-8">the destination</span><span 
class="ec-lmr-8">’s format.</span><span 
class="ec-lmr-8">” (</span><a 
 id="x12-4004"></a> <span 
class="ec-lmcsc-10x-x-80">ieee</span><span 
class="ec-lmr-8">, 2008) Note that, per </span><a 
 id="x12-4005"></a> <span 
class="ec-lmr-8">Risse, </span><span 
class="ec-lmr-8">“there is</span>
   <span 
class="ec-lmr-8">no indication whether or not a computation with </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 is exact even if</span>
   <span 
class="ec-lmr-8">all arguments are.</span><span 
class="ec-lmr-8">” The </span><span 
class="ec-lmcsc-10x-x-80">iso</span><span 
class="ec-lmr-8">/</span><span 
class="ec-lmcsc-10x-x-80">iec </span><span 
class="ec-lmr-8">9899 C standard confesses its own</span>
   <span 
class="ec-lmr-8">fallibility: </span><span 
class="ec-lmr-8">“The ﬂoating-point model is intended to clarify the</span>
   <span 
class="ec-lmr-8">description of each ﬂoating-point characteristic and does not require the</span>
   <span 
class="ec-lmr-8">ﬂoating-point arithmetic of the implementation to be identical</span><span 
class="ec-lmr-8">” (</span><a 
 id="x12-4006"></a> <span 
class="ec-lmcsc-10x-x-80">iso</span><span 
class="ec-lmr-8">/</span><span 
class="ec-lmcsc-10x-x-80">iec</span>
   <span 
class="ec-lmr-8">(2018), fn.</span><span 
class="ec-lmr-8"> 21).</span><a href="#x1-4003f11">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 89--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn12x0">  <sup class="textsuperscript">12</sup></a></span><span 
class="ec-lmr-8">For instance, left-shifting a ﬂoating-point value does not</span>
   <span 
class="ec-lmr-8">double it; we leave the mathematics of why as an exercise to the</span>
   <span 
class="ec-lmr-8">reader.</span><a href="#x1-4007f12">⤴</a></p></div>
       


   <div class="footnote-text">
   <!--l. 106--><p class="noindent" ><span class="footnote-mark"><a 
 id="fn13x0">  <sup class="textsuperscript">13</sup></a></span><span 
class="ec-lmr-8">Note that this is diﬀerent from the smallest representable value for a</span>
   <span 
class="ec-lmr-8">given bit width; e. g., for 32-bit single-precision ﬂoat the smallest</span>
   <span 
class="ec-lmr-8">representable value is</span> \(\texttt {0000.0000.0000.0000.0000.0000.0000.0001} = 1\times 10^{-45}\)<span 
class="ec-lmr-8">.</span><a href="#x1-4024f13">⤴</a></p></div> 


        <div class="footnote-text">
   <!--l. 162--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn14x0">  <sup class="textsuperscript">14</sup></a></span><span 
class="ec-lmr-8">We do not lay blame at the feet of any particular party; the facts</span>
   <span 
class="ec-lmr-8">are the facts. Indeed, a more recent revision of </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 leads with a call</span>
   <span 
class="ec-lmr-8">for portability: </span><span 
class="ec-lmr-8">“This standard provides a discipline for performing</span>
   <span 
class="ec-lmr-8">ﬂoating-point computation that yields results independent of whether the</span>
   <span 
class="ec-lmr-8">processing is done in hardware, software, or a combination of the two</span><span 
class="ec-lmr-8">” (</span><a 
 id="x15-7010"></a>
   <span 
class="ec-lmcsc-10x-x-80">ieee</span><span 
class="ec-lmr-8">, 2008).</span><a href="#x1-7009f14">⤴</a></p></div>
       


   <div class="footnote-text">
   <!--l. 178--><p class="noindent" ><span class="footnote-mark"><a 
 id="fn15x0">  <sup class="textsuperscript">15</sup></a></span><span 
class="ec-lmr-8">Subnormals are a convention that allows values smaller than the</span>
   <span 
class="ec-lmr-8">“normal</span><span 
class="ec-lmr-8">” </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 smallest non-zero value. They permit a graceﬂow</span>
   <span 
class="ec-lmr-8">underﬂow behavior, and can prevent an unintentional division by</span>
   <span 
class="ec-lmr-8">zero.</span><a href="#x1-8007f15">⤴</a></p></div> 


   <div class="footnote-text">
   <!--l. 178--><p class="noindent" ><span class="footnote-mark"><a 
 id="fn16x0">  <sup class="textsuperscript">16</sup></a></span><span 
class="ec-lmr-8">“Some processors do not support subnormal numbers in hardware</span><span 
class="ec-lmr-8">” (</span><a 
 id="x17-8009"></a>
   <span 
class="ec-lmr-8">Jones (2008), p.</span><span 
class="ec-lmr-8"> 338). (The risk is that this permits inadvertent</span>
   <span 
class="ec-lmr-8">division by zero.) Various chipsets solve this exceptional behavior</span>
   <span 
class="ec-lmr-8">diﬀerently.</span><a href="#x1-8008f16">⤴</a></p></div> 


        <div class="footnote-text">
   <!--l. 189--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn17x0">  <sup class="textsuperscript">17</sup></a></span><span 
class="ec-lmr-8">“C support for signaling NaNs, or for auxiliary information that</span>
   <span 
class="ec-lmr-8">could be encoded in NaNs, is problematic. Trap handling varies</span>
   <span 
class="ec-lmr-8">widely among implementations. Implementation mechanisms may</span>
   <span 
class="ec-lmr-8">trigger signaling NaNs, or fail to, in mysterious ways. The </span><span 
class="ec-lmcsc-10x-x-80">iec </span><span 
class="ec-lmr-8">60559</span>
   <span 
class="ec-lmr-8">ﬂoating-point standard recommends that NaNs propagate; but it does</span>
   <span 
class="ec-lmr-8">not require this and not all implementations do.</span><span 
class="ec-lmr-8">” (</span><a 
 id="x18-10003"></a> <span 
class="ec-lmr-8">Jones (2008),</span>
   <span 
class="ec-lmr-8">p.</span><span 
class="ec-lmr-8"> 339)</span><a href="#x1-10002f17">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 189--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn18x0">  <sup class="textsuperscript">18</sup></a></span><span 
class="ec-lmr-8">In Urbit, the Vere runtime uniﬁes NaNs, meaning that</span>
   <span 
class="ec-lmr-8">any bitwise information which may be encoded in the signiﬁcand</span>
   <span 
class="ec-lmr-8">ﬁeld</span><span 
class="ec-lmr-8">—the </span><span 
class="ec-lmr-8">“NaN payload</span><span 
class="ec-lmr-8">”</span><span 
class="ec-lmr-8">—is thrown away. This is called the “canonical</span>
   <span 
class="ec-lmr-8">NaN”.</span><a href="#x1-10004f18">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 220--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn19x0">  <sup class="textsuperscript">19</sup></a></span><span 
class="ec-lmr-8">The only signiﬁcant variation in the other real types in Hoon</span>
   <span 
class="ec-lmr-8">arises for quadruple-precision ﬂoating-point values </span><code class="lstinline"><span style="color:#000000">@rq</span></code> <span 
class="ec-lmr-8">which are</span>
   <span 
class="ec-lmr-8">represented in the runtime by a pair of uint64</span><span 
class="ec-lmr-8">_ts.</span><a href="#x1-13001f19">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 222--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn20x0">  <sup class="textsuperscript">20</sup></a></span><span 
class="ec-lmr-8">The decimal output is produced using the traditional Steele</span><span 
class="ec-lmr-8">–White</span>
   <span 
class="ec-lmr-8">Dragon4 algorithm (</span><a 
 id="x21-13003"></a> <span 
class="ec-lmr-8">Steele and White, 1991). It is worth considering</span>
   <span 
class="ec-lmr-8">upgrading Hoon from Dragon4 to Errol (</span><a 
 id="x21-13004"></a> <span 
class="ec-lmr-8">Andryso, Jhala, and Lerner,</span>
   <span 
class="ec-lmr-8">2016) for speed and accuracy.</span><a href="#x1-13002f20">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 224--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn21x0">  <sup class="textsuperscript">21</sup></a></span><span 
class="ec-lmr-8">In practice, of course, Urbit hews to recognized types, but the</span>
   <span 
class="ec-lmr-8">temptation to design new ﬂoating-point layouts is intriguing.</span><a href="#x1-13005f21">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 247--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn22x0">  <sup class="textsuperscript">22</sup></a></span><span 
class="ec-lmr-8">A shorthand for </span><span 
class="ec-lmri-8">jet-accelerated code</span><span 
class="ec-lmr-8">.</span><a href="#x1-13023f22">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 247--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn23x0">  <sup class="textsuperscript">23</sup></a></span><span 
class="ec-lmr-8">u3 functions are Urbit noun library functions. The sing union is a</span>
   <span 
class="ec-lmr-8">union of uint32</span><span 
class="ec-lmr-8">_t and SoftFloat ﬂoat32</span><span 
class="ec-lmr-8">_t types.</span><a href="#x1-13024f23">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 271--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn24x0">  <sup class="textsuperscript">24</sup></a></span><span 
class="ec-lmr-8">Support for </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 is similar for support for the Markdown</span>
   <span 
class="ec-lmr-8">markup language. Many platforms support a subset of Markdown coupled</span>
   <span 
class="ec-lmr-8">with platform-speciﬁc extensions. (See also </span><span 
class="ec-lmcsc-10x-x-80">sql</span><span 
class="ec-lmr-8">.) Internal references,</span>
   <span 
class="ec-lmcsc-10x-x-80">html</span><span 
class="ec-lmr-8">, inline LaTeX</span><span 
class="ec-lmr-8"> math mode, code block language speciﬁcation, and</span>
   <span 
class="ec-lmr-8">other features see varying levels of support with GitHub, Pandoc,</span>
   <span 
class="ec-lmr-8">Obsidian, and other editors and converters.</span><a href="#x1-14001f24">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 315--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn25x0">  <sup class="textsuperscript">25</sup></a></span><span 
class="ec-lmr-8">This can be mitigated in turn by the use of the volatile</span>
   <span 
class="ec-lmr-8">designation, but this is suﬃcient to illustrate the problem.</span><a href="#x1-14029f25">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 317--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn26x0">  <sup class="textsuperscript">26</sup></a></span><span 
class="ec-lmr-8">I was once asked by a retired computer science professor if such</span>
   <span 
class="ec-lmr-8">guarantees would make things easier. Well, at the end developer</span>
   <span 
class="ec-lmr-8">level!</span><a href="#x1-14030f26">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 319--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn27x0">  <sup class="textsuperscript">27</sup></a></span><span 
class="ec-lmr-8">The problem of exactness is not exactly the same as reproducibility,</span>
   <span 
class="ec-lmr-8">but it is related. Exactness means that the result is the same as if the</span>
   <span 
class="ec-lmr-8">calculation were carried out to inﬁnite precision and then rounded to the</span>
   <span 
class="ec-lmr-8">appropriate number of bits. Reproducibility means that the result is the</span>
   <span 
class="ec-lmr-8">same across diﬀerent platforms. Reproducibility requires identical</span>
   <span 
class="ec-lmr-8">outcomes from the same inputs, while exactness requires the correct</span>
   <span 
class="ec-lmr-8">answer regardless of algorithmic path.</span><a href="#x1-14035f27">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 335--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn28x0">  <sup class="textsuperscript">28</sup></a></span><span 
class="ec-lmr-8">Although not of grave consequence, the C language (as</span>
   <span 
class="ec-lmr-8">of C23) does not implement at least two types speciﬁed by </span><span 
class="ec-lmcsc-10x-x-80">ieee</span>
   <span 
class="ec-lmr-8">754-2019 and recent predecessors: binary128 quadruple precision and</span>
   <span 
class="ec-lmr-8">binary256 octuple precision. While neither are signiﬁcant losses, we</span>
   <span 
class="ec-lmr-8">also note that Urbit does not currently support a C-style long</span>
   <span 
class="ec-lmr-8">double type. C’s long double is 80 bits wide on some common</span>
   <span 
class="ec-lmr-8">consumer hardware, such as the x86-64 architecture, but is 128 bits</span>
   <span 
class="ec-lmr-8">wide on the 64-bit </span><span 
class="ec-lmcsc-10x-x-80">arm </span><span 
class="ec-lmr-8">architecture. (The situation is worse for</span>
   <span 
class="ec-lmr-8">Python, whose numpy.ﬂoat128 type eponymously advertises itself as</span>
   <span 
class="ec-lmr-8">quadruple precision but is in fact a regular 80-bit long double.) Some</span>
   <span 
class="ec-lmr-8">compilers and libraries do support quadruple-precision ﬂoating-point</span>
   <span 
class="ec-lmr-8">mathematics, such as </span><span 
class="ec-lmcsc-10x-x-80">gcc</span><span 
class="ec-lmr-8">’s </span><span 
class="ec-lmr-8">_</span><span 
class="ec-lmr-8">_ﬂoat128 type. We note that </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 80-bit</span>
   <span 
class="ec-lmr-8">extended-precision could be implemented using the </span><code class="lstinline"><span style="color:#000000">++fn</span></code> <span 
class="ec-lmr-8">core should</span>
   <span 
class="ec-lmr-8">demand arise.</span><a href="#x1-15001f28">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 337--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn29x0">  <sup class="textsuperscript">29</sup></a></span><span 
class="ec-lmr-8">Indeed, we do not know the future speciﬁcations which may be</span>
   <span 
class="ec-lmr-8">implemented to provide approximations of real values in either hardware</span>
   <span 
class="ec-lmr-8">or software.</span><a href="#x1-15002f29">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 357--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn30x0">  <sup class="textsuperscript">30</sup></a></span><span 
class="ec-lmr-8">In any case, this assumes a legible and enumerable set of</span>
   <span 
class="ec-lmr-8">behaviors for volatile which is, alas, not the case. </span><span 
class="ec-lmr-8">“volatile is a hint to</span>
   <span 
class="ec-lmr-8">the implementation to avoid aggressive optimization involving</span>
   <span 
class="ec-lmr-8">the object because the value of the object might be changed by</span>
   <span 
class="ec-lmr-8">means undetectable by an implementation</span><span 
class="ec-lmr-8">” (Jones (2008), p.</span><span 
class="ec-lmr-8"> 472).</span>
   <span 
class="ec-lmr-8">“Actions on objects so declared shall not be </span><span 
class="ec-lmr-8">‘optimized out</span><span 
class="ec-lmr-8">’ by an</span>
   <span 
class="ec-lmr-8">implementation or reordered except as permitted by the rules for</span>
   <span 
class="ec-lmr-8">evaluating expressions</span><span 
class="ec-lmr-8">” (</span><span 
class="ec-lmri-8">ibid</span><span 
class="ec-lmr-8">, p.</span><span 
class="ec-lmr-8"> 1500). </span><span 
class="ec-lmr-8">“The volatile qualiﬁer only</span>
   <span 
class="ec-lmr-8">indicates that the value of an object may change in ways unknown to the</span>
   <span 
class="ec-lmr-8">translator (therefore the quality of generated machine code may</span>
   <span 
class="ec-lmr-8">be degraded because a translator cannot make use of previous</span>
   <span 
class="ec-lmr-8">accesses to optimize the current access)</span><span 
class="ec-lmr-8">” (</span><span 
class="ec-lmri-8">ibid</span><span 
class="ec-lmr-8">, p.</span><span 
class="ec-lmr-8"> 963). The same</span>
   <span 
class="ec-lmr-8">author provides examples of C code that is ambiguous in volatile’s</span>
   <span 
class="ec-lmr-8">semantics, pp.</span><span 
class="ec-lmr-8"> 1290</span><span 
class="ec-lmr-8">–1291; and undeﬁned in volatile’s semantics,</span>
   <span 
class="ec-lmr-8">pp.</span><span 
class="ec-lmr-8"> 1482</span><span 
class="ec-lmr-8">–1483.</span><a href="#x1-16002f30">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 357--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn31x0">  <sup class="textsuperscript">31</sup></a></span><span 
class="ec-lmr-8">“What constitutes an access to an object that has volatile-qualiﬁed</span>
   <span 
class="ec-lmr-8">type is implementation-deﬁned</span><span 
class="ec-lmr-8">” (</span><span 
class="ec-lmri-8">ibid</span><span 
class="ec-lmr-8">, p.</span><span 
class="ec-lmr-8"> 1488). </span><span 
class="ec-lmr-8">“Volatile-qualiﬁed</span>
   <span 
class="ec-lmr-8">objects can also be aﬀected by translator optimizations</span><span 
class="ec-lmr-8">” (</span><span 
class="ec-lmri-8">ibid</span><span 
class="ec-lmr-8">, p.</span><span 
class="ec-lmr-8"> 1490).</span>
   <span 
class="ec-lmr-8">The C novice may at this point wonder what the intended utility of</span>
   <span 
class="ec-lmr-8">volatile in fact is: </span><span 
class="ec-lmr-8">“[a] volatile declaration may be used to describe an</span>
   <span 
class="ec-lmr-8">object corresponding to a memory-mapped input/output port or an</span>
   <span 
class="ec-lmr-8">object accessed by an asynchronously interrupting function</span><span 
class="ec-lmr-8">” (</span><span 
class="ec-lmri-8">ibid</span><span 
class="ec-lmr-8">,</span>
   <span 
class="ec-lmr-8">p.</span><span 
class="ec-lmr-8"> 1499).</span><a href="#x1-16003f31">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 359--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn32x0">  <sup class="textsuperscript">32</sup></a></span><span 
class="ec-lmr-8">“The ﬂoating-point environment access and modiﬁcation is only</span>
   <span 
class="ec-lmr-8">meaningful when #pragma STDC FENV</span><span 
class="ec-lmr-8">_ACCESS is set to ON. </span><span 
class="ec-lmr-8">… In</span>
   <span 
class="ec-lmr-8">practice, few current compilers, such as HP aCC, Oracle Studio, and </span><span 
class="ec-lmcsc-10x-x-80">ibm</span>
   <span 
class="ec-lmr-8">XL, support the #pragma explicitly, but most compilers allow</span>
   <span 
class="ec-lmr-8">meaningful access to the ﬂoating-point environment anyway.</span><span 
class="ec-lmr-8">” (</span><a 
 id="x33-16005"></a> <span 
class="ec-lmr-8">C++</span>
   <span 
class="ec-lmr-8">Reference, 2023)</span><a href="#x1-16004f32">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 363--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn33x0">  <sup class="textsuperscript">33</sup></a></span><span 
class="ec-lmr-8">The possibility of circumscribing the set of permissible </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754</span>
   <span 
class="ec-lmr-8">operations, which may aﬀord a diﬀerent approach to this problem but</span>
   <span 
class="ec-lmr-8">seems similarly susceptible of shipwreck, is explored in a subsequent</span>
   <span 
class="ec-lmr-8">section, </span><span 
class="ec-lmri-8">q.v.</span><a href="#x1-16007f33">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 397--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn34x0">  <sup class="textsuperscript">34</sup></a></span><span 
class="ec-lmr-8">Indeed, something like this cache system was employed on Sun</span>
   <span 
class="ec-lmcsc-10x-x-80">sparc </span><span 
class="ec-lmr-8">architecture, as discussed in Section </span><a 
href="mss.html#x1-230004.4"><span 
class="ec-lmr-8">4.4</span><!--tex4ht:ref: stored-results --></a> <span 
class="ec-lmr-8">.</span><a href="#x1-20001f34">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 405--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn35x0">  <sup class="textsuperscript">35</sup></a></span><span 
class="ec-lmr-8">“The current release supports ﬁve binary formats: 16-bit</span>
   <span 
class="ec-lmr-8">half-precision, 32-bit single-precision, 64-bit double-precision, 80-bit</span>
   <span 
class="ec-lmr-8">double-extended-precision, and 128-bit quadruple-precision</span><span 
class="ec-lmr-8">” (Hauser,</span>
   <span 
class="ec-lmr-8">2018).</span><a href="#x1-21002f35">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 407--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn36x0">  <sup class="textsuperscript">36</sup></a></span><span 
class="ec-lmr-8">“There are several 680x0-based Macintosh computers that do not</span>
   <span 
class="ec-lmr-8">contain ﬂoating-point coprocessors</span><span 
class="ec-lmr-8">” (</span><a 
 id="x37-21004"></a> <span 
class="ec-lmr-8">Apple Computer, 1994); on the</span>
   <span 
class="ec-lmr-8">other hand, </span><span 
class="ec-lmr-8">“ﬂoating-point calculations are performed even faster under</span>
   <span 
class="ec-lmr-8">the </span><span 
class="ec-lmr-8">… emulator than on a real 680x0-based Macintosh computer,</span><span 
class="ec-lmr-8">”</span>
   <span 
class="ec-lmr-8">indicating that optimized software acceleration is possible, modulo</span>
   <span 
class="ec-lmr-8">chipset versions and tuned libraries. The PowerPC 601, introduced in</span>
   <span 
class="ec-lmr-8">1991, had a native </span><span 
class="ec-lmcsc-10x-x-80">fpu</span><span 
class="ec-lmr-8">.</span><a href="#x1-21003f36">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 409--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn37x0">  <sup class="textsuperscript">37</sup></a></span><span 
class="ec-lmr-8">To correctly calculate a trigonometric function for double may</span>
   <span 
class="ec-lmr-8">take over a hundred bits of precision before correct rounding can be</span>
   <span 
class="ec-lmr-8">determined. Furthermore, the C math.h implementation of</span> \(\sin \) <span 
class="ec-lmr-8">may or may</span>
   <span 
class="ec-lmr-8">not use fsin.</span><a href="#x1-21008f37">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 425--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn38x0">  <sup class="textsuperscript">38</sup></a></span><span 
class="ec-lmr-8">The memory implications of these are not necessary here, but</span>
   <span 
class="ec-lmr-8">take place in diﬀerent arenas: the runtime versus the Arvo noun</span>
   <span 
class="ec-lmr-8">arena.</span><a href="#x1-22005f38">⤴</a></p></div>
       


   <div class="footnote-text">
   <!--l. 435--><p class="noindent" ><span class="footnote-mark"><a 
 id="fn39x0">  <sup class="textsuperscript">39</sup></a></span><span 
class="ec-lmr-8">Cf. Jones’ citation of </span><a 
 id="x40-23003"></a> <span 
class="ec-lmr-8">Citron, Feitelson, and Rudolph.</span><a href="#x1-23002f39">⤴</a></p></div> 


        <div class="footnote-text">
   <!--l. 442--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn40x0">  <sup class="textsuperscript">40</sup></a></span><span 
class="ec-lmr-8">What constitutes </span><span 
class="ec-lmr-8">“suspicion</span><span 
class="ec-lmr-8">” is only sparsely elaborated by</span>
   <span 
class="ec-lmr-8">Kahan in that article.</span><a href="#x1-23005f40">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 452--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn41x0">  <sup class="textsuperscript">41</sup></a></span><span 
class="ec-lmr-8">See particularly the note on </span><span 
class="ec-lmr-8">“Common Implementations</span><span 
class="ec-lmr-8">” on</span>
   <span 
class="ec-lmr-8">p.</span><span 
class="ec-lmr-8"> 346 of Jones (2008).</span><a href="#x1-25003f41">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 458--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn42x0">  <sup class="textsuperscript">42</sup></a></span><span 
class="ec-lmr-8">“Using our default settings, reproducibly summing</span> \(n\) <span 
class="ec-lmr-8">ﬂoating point</span>
   <span 
class="ec-lmr-8">types requires approximately</span> \(9n\) <span 
class="ec-lmr-8">ﬂoating point operations (arithmetic,</span>
   <span 
class="ec-lmr-8">comparison, and absolute value). In theory, this count can be reduced to</span> \(5n\)
   <span 
class="ec-lmr-8">using the new ‘augmented addition’ and ‘maximum magnitude’</span>
   <span 
class="ec-lmr-8">instructions in the proposed </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">Floating Point Standard 754-2018.</span><span 
class="ec-lmr-8">”</span>
   <span 
class="ec-lmr-8">(Ahrens, Nguyen, and Demmel, 2018)</span><a href="#x1-25005f42">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 466--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn43x0">  <sup class="textsuperscript">43</sup></a></span><span 
class="ec-lmr-8">See also </span><a 
 id="x44-27003"></a> <span 
class="ec-lmr-8">Gustafson (2017), </span><a 
 id="x44-27004"></a> <span 
class="ec-lmr-8">Gustafson (2017), and </span><a 
 id="x44-27005"></a> <span 
class="ec-lmr-8">Gustafson</span>
   <span 
class="ec-lmr-8">and Yonemoto (2017).</span><a href="#x1-27002f43">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 483--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn44x0">  <sup class="textsuperscript">44</sup></a></span><span 
class="ec-lmr-8">“One solution to implementing ﬂoating-point types on processors</span>
   <span 
class="ec-lmr-8">that support ﬁxed-point types is to convert the source containing</span>
   <span 
class="ec-lmr-8">ﬂoating-point data operations to make calls to a ﬁxed-point library</span><span 
class="ec-lmr-8">” (</span><a 
 id="x45-29002"></a>
   <span 
class="ec-lmr-8">Jones (2008), p.</span><span 
class="ec-lmr-8"> 346). Note that the sense of our current interest is</span>
   <span 
class="ec-lmr-8">reversed.</span><a href="#x1-29001f44">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 492--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn45x0">  <sup class="textsuperscript">45</sup></a></span><span 
class="ec-lmr-8">Particularly as regards co-generation of Hoon and C/Rust, or</span>
   <span 
class="ec-lmr-8">formal proofs.</span><a href="#x1-30001f45">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 492--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn46x0">  <sup class="textsuperscript">46</sup></a></span><span 
class="ec-lmr-8">The Vere runtime supports a debugging ﬂag which runs both the</span>
   <span 
class="ec-lmr-8">Nock and the jet and checks for identical results.</span><a href="#x1-30002f46">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 494--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn47x0">  <sup class="textsuperscript">47</sup></a></span><span 
class="ec-lmr-8">By </span><span 
class="ec-lmr-8">“current era</span><span 
class="ec-lmr-8">”, we mean after the last global network breach</span>
   <span 
class="ec-lmr-8">on </span><span 
class="ec-lmr-8">~2020.12.8 (</span><a 
 id="x48-30004"></a> <span 
class="ec-lmr-8">Tlon Corporation, 2020).</span><a href="#x1-30003f47">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 498--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn48x0">  <sup class="textsuperscript">48</sup></a></span><span 
class="ec-lmr-8">Linear AlGebra in hOON</span><a href="#x1-31001f48">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 512--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn49x0">  <sup class="textsuperscript">49</sup></a></span><span 
class="ec-lmr-8">It is a worth a ﬁnal digression to address reproducibility on</span>
   <span 
class="ec-lmr-8">parallel systems. We do not consider this a design goal for Lagoon at the</span>
   <span 
class="ec-lmr-8">current time. Operations like reduction take place on a single computer;</span>
   <span 
class="ec-lmr-8">while jets may in principle utilize parallelism their points of entry and</span>
   <span 
class="ec-lmr-8">exit are unique. However, we note that the ReproBLAS project has</span>
   <span 
class="ec-lmr-8">addressed this issue in the context of reproducible parallelism (</span><a 
 id="x50-31015"></a> <span 
class="ec-lmr-8">Ahrens,</span>
   <span 
class="ec-lmr-8">Nguyen, and Demmel, 2018), as have </span><a 
 id="x50-31016"></a> <span 
class="ec-lmr-8">Chohra, Langlois, and Parello</span>
   <span 
class="ec-lmr-8">(2016).</span><a href="#x1-31014f49">⤴</a></p></div>
       


        <div class="footnote-text">
   <!--l. 530--><p class="indent" >     <span class="footnote-mark"><a 
 id="fn50x0">  <sup class="textsuperscript">50</sup></a></span><span 
class="ec-lmr-8">Cf. UrWasm, which as a WebAssembly implementation directly</span>
   <span 
class="ec-lmr-8">relies on ﬂoating-point computations (</span><a 
 id="x51-32014"></a> <span 
class="ec-lmr-8">~dozreg-toplud, 2023) (see e. g.</span><span 
class="ec-lmr-8"> </span><a 
 id="x51-32015"></a>
   <span 
class="ec-lmr-8">@KloudKoder (2022) for a discussion of the issues involved, and in</span>
   <span 
class="ec-lmr-8">particular </span><a 
 id="x51-32016"></a> <span 
class="ec-lmr-8">~dozreg-toplud, pp. 133</span><span 
class="ec-lmr-8">–150 in this issue), </span><a 
href="https://github.com/Quodss/urwasm" ><span 
class="ec-lmr-8">Quodss/urwasm</span></a><span 
class="ec-lmr-8">;</span>
   <span 
class="ec-lmr-8">/lib/math, implemented purely in Hoon, </span><a 
href="https://github.com/sigilante/libmath" ><span 
class="ec-lmr-8">sigilante/libmath</span></a><span 
class="ec-lmr-8">; and</span>
   <span 
class="ec-lmr-8">Lagoon, which includes </span><span 
class="ec-lmcsc-10x-x-80">ieee </span><span 
class="ec-lmr-8">754 operations with its linear algebra</span>
   <span 
class="ec-lmr-8">library, </span><a 
href="https://github.com/urbit/numerics" ><span 
class="ec-lmr-8">urbit/numerics</span></a> <span 
class="ec-lmr-8">pending development and integration into</span>
   <span 
class="ec-lmr-8">Urbit.</span><a href="#x1-32013f50">⤴</a></p></div>
       

</body> 
</html>
                                                


